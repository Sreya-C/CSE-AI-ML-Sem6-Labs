{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcrljJHcq4Kf",
        "outputId": "780387f3-164d-49ee-bfd8-c119f3b30651"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['/content/cats_and_dogs_filtered/train/cats', '/content/cats_and_dogs_filtered/train/dogs']\n",
            "['/content/cats_and_dogs_filtered/validation/cats', '/content/cats_and_dogs_filtered/validation/dogs']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /root/.cache/torch/hub/v0.10.0.zip\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:01<00:00, 136MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
            "  )\n",
            ")\n",
            "Epoch:  1\n",
            "\tTraining: \n",
            "\t\tAccuracy: 90.5%\n",
            "\t\tLoss: 0.2199\n",
            "\tValidation: \n",
            "\t\tAccuracy: 95.7%\n",
            "\t\tLoss: 0.112\n",
            "Epoch:  2\n",
            "\tTraining: \n",
            "\t\tAccuracy: 95.5%\n",
            "\t\tLoss: 0.1155\n",
            "\tValidation: \n",
            "\t\tAccuracy: 95.4%\n",
            "\t\tLoss: 0.1025\n",
            "Epoch:  3\n",
            "\tTraining: \n",
            "\t\tAccuracy: 96.15%\n",
            "\t\tLoss: 0.09568\n",
            "\tValidation: \n",
            "\t\tAccuracy: 96.6%\n",
            "\t\tLoss: 0.08742\n",
            "Epoch:  4\n",
            "\tTraining: \n",
            "\t\tAccuracy: 97.05%\n",
            "\t\tLoss: 0.07523\n",
            "\tValidation: \n",
            "\t\tAccuracy: 96.6%\n",
            "\t\tLoss: 0.08324\n",
            "Epoch:  5\n",
            "\tTraining: \n",
            "\t\tAccuracy: 97.9%\n",
            "\t\tLoss: 0.06053\n",
            "\tValidation: \n",
            "\t\tAccuracy: 96.5%\n",
            "\t\tLoss: 0.08814\n",
            "Epoch:  6\n",
            "\tTraining: \n",
            "\t\tAccuracy: 98.55%\n",
            "\t\tLoss: 0.05071\n",
            "\tValidation: \n",
            "\t\tAccuracy: 96.5%\n",
            "\t\tLoss: 0.07952\n",
            "Epoch:  7\n",
            "\tTraining: \n",
            "\t\tAccuracy: 98.75%\n",
            "\t\tLoss: 0.04093\n",
            "\tValidation: \n",
            "\t\tAccuracy: 96.3%\n",
            "\t\tLoss: 0.09189\n"
          ]
        }
      ],
      "source": [
        "import PIL.Image as Image\n",
        "import pandas as pd\n",
        "import glob\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torchvision.models import AlexNet_Weights\n",
        "from torchvision import transforms as T\n",
        "\n",
        "epochs = 7\n",
        "batch_size_train = 16\n",
        "batch_size_test = 100\n",
        "lr = 0.001\n",
        "weight_decay = 0.001\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "transform = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Resize([224,224]),\n",
        "    T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self,transform=None,string=\"train\"):\n",
        "        self.imgs_path = \"/content/cats_and_dogs_filtered/\" + string + \"/\"\n",
        "        file_list = glob.glob(self.imgs_path+\"*\")\n",
        "        print(file_list)\n",
        "        self.data = []\n",
        "        for class_path in file_list:\n",
        "            class_name = class_path.split(\"/\")[-1]\n",
        "            for img_path in glob.glob(class_path+\"/*.jpg\"):\n",
        "                self.data.append([img_path,class_name])\n",
        "        self.class_map = {\"dogs\":0,\"cats\":1}\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        img_path,class_name = self.data[idx]\n",
        "        img = Image.open(img_path)\n",
        "        class_id = self.class_map[class_name]\n",
        "        class_id = torch.tensor(class_id)\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img,class_id\n",
        "\n",
        "def get_model():\n",
        "    model = torch.hub.load('pytorch/vision:v0.10.0','alexnet',weights=AlexNet_Weights.DEFAULT)\n",
        "    model.features.requires_grad=False\n",
        "    model.classifier = nn.Sequential(\n",
        "    *model.classifier[:-1],\n",
        "    nn.Linear(4096,2,bias=True))\n",
        "    return model\n",
        "\n",
        "def train(model,train_loader,criterion,optimizer,device=\"cpu\"):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    for batch_idx, (data,target) in enumerate(train_loader):\n",
        "        data, target = data.to(device),target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output,target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()*len(data)\n",
        "        pred = output.data.max(1,keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "    running_loss /= len(train_loader.dataset)\n",
        "    acc = 100*correct/len(train_loader.dataset)\n",
        "    return acc,running_loss\n",
        "\n",
        "def test(model,test_loader,criterion,device=\"cpu\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data,target in test_loader:\n",
        "            data,target = data.to(device),target.to(device)\n",
        "            output = model(data)\n",
        "            running_loss += criterion(output,target).item()*len(data)\n",
        "            pred = output.data.max(1,keepdim=True)[1]\n",
        "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "    running_loss /= len(test_loader.dataset)\n",
        "    acc = 100. * correct / len(test_loader.dataset)\n",
        "    return acc,running_loss\n",
        "\n",
        "train_dataset = MyDataset(transform,\"train\")\n",
        "train_loader = DataLoader(train_dataset,batch_size = batch_size_train, shuffle=True)\n",
        "test_dataset = MyDataset(transform,\"validation\")\n",
        "test_loader = DataLoader(test_dataset,batch_size = batch_size_test, shuffle=True)\n",
        "\n",
        "modelA = get_model()\n",
        "modelA = modelA.to(device)\n",
        "print();print();\n",
        "print(modelA)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizerA = optim.SGD(modelA.parameters(),lr=lr,weight_decay=weight_decay)\n",
        "for epoch in range(1,epochs+1):\n",
        "    print(\"Epoch: \",epoch)\n",
        "    print(\"\\tTraining: \")\n",
        "    train_acc, train_loss = train(modelA, train_loader, criterion, optimizerA, device)\n",
        "    print(\"\\t\\tAccuracy: {:.4}%\".format(train_acc))\n",
        "    print(\"\\t\\tLoss: {:.4}\".format(train_loss))\n",
        "\n",
        "    print(\"\\tValidation: \")\n",
        "    test_acc, test_loss = test(modelA, test_loader, criterion, device)\n",
        "    print(\"\\t\\tAccuracy: {:.4}%\".format(test_acc))\n",
        "    print(\"\\t\\tLoss: {:.4}\".format(test_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVuWp6eik7EW",
        "outputId": "b49015f1-4a01-4745-e4e0-f75b960467f4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "\tTraining: \n",
            "\t\tAccuracy: 1.464e+03%\n",
            "\t\tLoss: 0.01461\n",
            "\tValidation: \n",
            "\t\tAccuracy: 96.3%\n",
            "\t\tLoss: 0.1102\n",
            "Epoch: 2\n",
            "\tTraining: \n",
            "\t\tAccuracy: 1.53e+03%\n",
            "\t\tLoss: 0.01061\n",
            "\tValidation: \n",
            "\t\tAccuracy: 96.5%\n",
            "\t\tLoss: 0.09395\n",
            "Epoch: 3\n",
            "\tTraining: \n",
            "\t\tAccuracy: 1.54e+03%\n",
            "\t\tLoss: 0.006713\n",
            "\tValidation: \n",
            "\t\tAccuracy: 96.0%\n",
            "\t\tLoss: 0.09202\n",
            "Epoch: 4\n",
            "\tTraining: \n",
            "\t\tAccuracy: 1.556e+03%\n",
            "\t\tLoss: 0.00773\n",
            "\tValidation: \n",
            "\t\tAccuracy: 96.4%\n",
            "\t\tLoss: 0.08635\n",
            "Epoch: 5\n",
            "\tTraining: \n",
            "\t\tAccuracy: 1.562e+03%\n",
            "\t\tLoss: 0.001947\n",
            "\tValidation: \n",
            "\t\tAccuracy: 96.8%\n",
            "\t\tLoss: 0.08097\n",
            "Epoch: 6\n",
            "\tTraining: \n",
            "\t\tAccuracy: 1.575e+03%\n",
            "\t\tLoss: 0.02008\n",
            "\tValidation: \n",
            "\t\tAccuracy: 95.9%\n",
            "\t\tLoss: 0.08674\n",
            "Epoch: 7\n",
            "\tTraining: \n",
            "\t\tAccuracy: 1.582e+03%\n",
            "\t\tLoss: 0.004256\n",
            "\tValidation: \n",
            "\t\tAccuracy: 96.8%\n",
            "\t\tLoss: 0.08211\n"
          ]
        }
      ],
      "source": [
        "regularization = 2\n",
        "\n",
        "def train_with_regularization(model,train_loader,criterion,optimizer,regularization=2,lamda=0.001,device=\"cpu\"):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    for bacth_idx,(inputs,target) in enumerate(train_loader):\n",
        "        inputs, target = inputs.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(inputs)\n",
        "        optimizer.step()\n",
        "        loss = criterion(output,target)\n",
        "        running_loss = loss.item()*len(inputs)\n",
        "        norm = sum(torch.norm(p,regularization) for p in model.parameters())\n",
        "        loss = loss + lamda*norm\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pred = output.data.max(1,keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "    running_loss /= len(train_loader)\n",
        "    acc = 100. * correct / len(train_loader)\n",
        "    return acc, running_loss\n",
        "\n",
        "modelB = get_model()\n",
        "modelB = modelB.to(device)\n",
        "\n",
        "optimizerB = optim.SGD(modelB.parameters(), lr=lr)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    print(f\"Epoch: {epoch}\")\n",
        "\n",
        "    print(\"\\tTraining: \")\n",
        "    train_acc, train_loss = train_with_regularization(modelB, train_loader, criterion, optimizerB, regularization, weight_decay, device)\n",
        "    print(\"\\t\\tAccuracy: {:.4}%\".format(train_acc))\n",
        "    print(\"\\t\\tLoss: {:.4}\".format(train_loss))\n",
        "\n",
        "    print(\"\\tValidation: \")\n",
        "    test_acc, test_loss = test(modelB, test_loader, criterion, device)\n",
        "    print(\"\\t\\tAccuracy: {:.4}%\".format(test_acc))\n",
        "    print(\"\\t\\tLoss: {:.4}\".format(test_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZE8YS8JKmL9E",
        "outputId": "b9558b3e-425d-4a79-82ff-314522e7f0cf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "\tTraining: \n",
            "\t\tAccuracy: 1.455e+03%\n",
            "\t\tLoss: 0.00657\n",
            "\tValidation: \n",
            "\t\tAccuracy: 96.1%\n",
            "\t\tLoss: 0.1126\n",
            "Epoch: 2\n",
            "\tTraining: \n",
            "\t\tAccuracy: 1.535e+03%\n",
            "\t\tLoss: 0.009093\n",
            "\tValidation: \n",
            "\t\tAccuracy: 96.3%\n",
            "\t\tLoss: 0.09783\n",
            "Epoch: 3\n",
            "\tTraining: \n",
            "\t\tAccuracy: 1.545e+03%\n",
            "\t\tLoss: 0.01068\n",
            "\tValidation: \n",
            "\t\tAccuracy: 96.3%\n",
            "\t\tLoss: 0.08779\n",
            "Epoch: 4\n",
            "\tTraining: \n",
            "\t\tAccuracy: 1.56e+03%\n",
            "\t\tLoss: 0.007282\n",
            "\tValidation: \n",
            "\t\tAccuracy: 96.3%\n",
            "\t\tLoss: 0.08739\n",
            "Epoch: 5\n",
            "\tTraining: \n",
            "\t\tAccuracy: 1.562e+03%\n",
            "\t\tLoss: 0.01311\n",
            "\tValidation: \n",
            "\t\tAccuracy: 96.5%\n",
            "\t\tLoss: 0.08619\n",
            "Epoch: 6\n",
            "\tTraining: \n",
            "\t\tAccuracy: 1.57e+03%\n",
            "\t\tLoss: 0.01763\n",
            "\tValidation: \n",
            "\t\tAccuracy: 96.5%\n",
            "\t\tLoss: 0.08133\n",
            "Epoch: 7\n",
            "\tTraining: \n",
            "\t\tAccuracy: 1.574e+03%\n",
            "\t\tLoss: 0.001077\n",
            "\tValidation: \n",
            "\t\tAccuracy: 96.4%\n",
            "\t\tLoss: 0.07915\n"
          ]
        }
      ],
      "source": [
        "regularization = 1\n",
        "\n",
        "def train_with_regularization_1(model,train_loader,criterion,optimizer,regularization=2,lamda=0.001,device=\"cpu\"):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    for bacth_idx,(inputs,target) in enumerate(train_loader):\n",
        "        inputs, target = inputs.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(inputs)\n",
        "        optimizer.step()\n",
        "        loss = criterion(output,target)\n",
        "        running_loss = loss.item()*len(inputs)\n",
        "        norm = sum(torch.norm(p,regularization) for p in model.parameters())\n",
        "        loss = loss + lamda*norm\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pred = output.data.max(1,keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "    running_loss /= len(train_loader)\n",
        "    acc = 100. * correct / len(train_loader)\n",
        "    return acc, running_loss\n",
        "\n",
        "modelC = get_model()\n",
        "modelC = modelC.to(device)\n",
        "\n",
        "optimizerC = optim.SGD(modelC.parameters(), lr=lr)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    print(f\"Epoch: {epoch}\")\n",
        "\n",
        "    print(\"\\tTraining: \")\n",
        "    train_acc, train_loss = train_with_regularization_1(modelC, train_loader, criterion, optimizerC, regularization, weight_decay, device)\n",
        "    print(\"\\tAccuracy: {:.4}%\".format(train_acc))\n",
        "    print(\"\\tLoss: {:.4}\".format(train_loss))\n",
        "\n",
        "    print(\"\\tValidation: \")\n",
        "    test_acc, test_loss = test(modelC, test_loader, criterion, device)\n",
        "    print(\"\\tAccuracy: {:.4}%\".format(test_acc))\n",
        "    print(\"\\tLoss: {:.4}\".format(test_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OKruWwmTk7wc",
        "outputId": "d64edc98-3dfd-43e0-a561-9fec140f2227"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Linear(in_features=4096, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
            "  )\n",
            ")\n",
            "Without Dropout\n",
            "Epoch: 1\n",
            "Training: \n",
            "\tAccuracy: 1.395e+03%\n",
            "\tLoss: 5.734\n",
            "Validation: \n",
            "\tAccuracy: 9.07e+03%\n",
            "\tLoss: 0.002393\n",
            "Epoch: 2\n",
            "Training: \n",
            "\tAccuracy: 1.512e+03%\n",
            "\tLoss: 2.422\n",
            "Validation: \n",
            "\tAccuracy: 9.55e+03%\n",
            "\tLoss: 0.001374\n",
            "Epoch: 3\n",
            "Training: \n",
            "\tAccuracy: 1.541e+03%\n",
            "\tLoss: 1.639\n",
            "Validation: \n",
            "\tAccuracy: 9.44e+03%\n",
            "\tLoss: 0.001447\n",
            "Epoch: 4\n",
            "Training: \n",
            "\tAccuracy: 1.553e+03%\n",
            "\tLoss: 1.236\n",
            "Validation: \n",
            "\tAccuracy: 9.62e+03%\n",
            "\tLoss: 0.001107\n",
            "Epoch: 5\n",
            "Training: \n",
            "\tAccuracy: 1.57e+03%\n",
            "\tLoss: 0.9073\n",
            "Validation: \n",
            "\tAccuracy: 9.53e+03%\n",
            "\tLoss: 0.00104\n",
            "Epoch: 6\n",
            "Training: \n",
            "\tAccuracy: 1.576e+03%\n",
            "\tLoss: 0.6523\n",
            "Validation: \n",
            "\tAccuracy: 9.58e+03%\n",
            "\tLoss: 0.001064\n",
            "Epoch: 7\n",
            "Training: \n",
            "\tAccuracy: 1.579e+03%\n",
            "\tLoss: 0.5325\n",
            "Validation: \n",
            "\tAccuracy: 9.54e+03%\n",
            "\tLoss: 0.001035\n",
            "Epoch: 8\n",
            "Training: \n",
            "\tAccuracy: 1.584e+03%\n",
            "\tLoss: 0.3738\n",
            "Validation: \n",
            "\tAccuracy: 9.54e+03%\n",
            "\tLoss: 0.001004\n",
            "Epoch: 9\n",
            "Training: \n",
            "\tAccuracy: 1.587e+03%\n",
            "\tLoss: 0.286\n",
            "Validation: \n",
            "\tAccuracy: 9.52e+03%\n",
            "\tLoss: 0.001067\n",
            "Epoch: 10\n",
            "Training: \n",
            "\tAccuracy: 1.588e+03%\n",
            "\tLoss: 0.2305\n",
            "Validation: \n",
            "\tAccuracy: 9.55e+03%\n",
            "\tLoss: 0.001022\n",
            "With Dropout\n",
            "Epoch: 1\n",
            "Training:\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'Tensor' object has no attribute '4'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-edc4d6b1cfc4>\u001b[0m in \u001b[0;36m<cell line: 145>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    147\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\tAccuracy: {.4}%\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\tLoss: {.4}%\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute '4'"
          ]
        }
      ],
      "source": [
        "import PIL.Image as Image\n",
        "import pandas as pd\n",
        "import glob\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torchvision.models import AlexNet_Weights\n",
        "from torchvision import transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = 10\n",
        "batch_size_train = 16\n",
        "batch_size_test = 100\n",
        "lr = 0.001\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "transform = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Resize([224,224]),\n",
        "    T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n",
        "classes = {'dogs':0,'cats':1}\n",
        "\n",
        "no_dropout = {'train':[],'test':[]}\n",
        "dropout = {'train':[],'test':[]}\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self,transform=None,string=\"train\"):\n",
        "    self.imgs_path = \"/content/cats_and_dogs_filtered/\" + string + \"/\"\n",
        "    file_list = glob.glob(self.imgs_path+\"*\")\n",
        "    self.data = []\n",
        "    for class_path in file_list:\n",
        "      class_name = class_path.split(\"/\")[-1]\n",
        "      for img_path in glob.glob(class_path+\"/*.jpg\"):\n",
        "        self.data.append([img_path,class_name])\n",
        "    self.class_map = {\"dogs\":0,\"cats\":1}\n",
        "    self.transform=transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    img_path,class_name = self.data[idx]\n",
        "    img = Image.open(img_path)\n",
        "    class_id = self.class_map[class_name]\n",
        "    class_id = torch.tensor(class_id)\n",
        "    if self.transform:\n",
        "      img = self.transform(img)\n",
        "    return img,class_id\n",
        "\n",
        "def get_model():\n",
        "  model = torch.hub.load(\"pytorch/vision:v0.10.0\",\"alexnet\",weights=AlexNet_Weights.DEFAULT)\n",
        "  model.features.requires_grad = False\n",
        "  model.classifier = nn.Sequential(\n",
        "      nn.Linear(256*6*6,4096),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Linear(4096,4096),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Linear(4096,2),\n",
        "  )\n",
        "  return model\n",
        "\n",
        "model1 = get_model().to(device)\n",
        "print(model1)\n",
        "\n",
        "dropout = 0.1\n",
        "def model_with_dropout(dropout=0.5):\n",
        "  model = torch.hub.load(\"pytorch/vision:v0.10.0\",\"alexnet\",weights=AlexNet_Weights.DEFAULT)\n",
        "  model.features.requires_grad = False\n",
        "  model.classifier = nn.Sequential(\n",
        "      nn.Dropout(p=dropout),\n",
        "      nn.Linear(256*6*6,4096),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Dropout(p=dropout),\n",
        "      nn.Linear(4096,4096),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Linear(4096,2),\n",
        "  )\n",
        "  return model\n",
        "\n",
        "model2 = model_with_dropout().to(device)\n",
        "print(model2)\n",
        "\n",
        "def train(model,train_loader,criterion,optimizer,deviec=\"cpu\"):\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  correct = 0\n",
        "  for batch_idx, (inputs,target) in enumerate(train_loader):\n",
        "    inputs,target = inputs.to(device),target.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs,target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    preds = outputs.data.max(1,keepdim=True)[1]\n",
        "    running_loss += loss.item()*len(inputs)\n",
        "    correct += preds.eq(target.data.view_as(preds)).sum()\n",
        "  running_loss /= len(train_loader)\n",
        "  acc = 100. * correct / len(train_loader)\n",
        "  return acc,running_loss\n",
        "\n",
        "def test(model,test_loader,criterion,device=\"cpu\"):\n",
        "  model.eval()\n",
        "  running_loss = 0.0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for inputs,target in test_loader:\n",
        "      inputs,target = inputs.to(device),target.to(device)\n",
        "      output = model(inputs)\n",
        "      loss = criterion(output,target)\n",
        "      running_loss += loss.item()\n",
        "      pred = output.data.max(1,keepdim=True)[1]\n",
        "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "  running_loss /= len(test_loader)*len(inputs)\n",
        "  acc = 100. * correct / len(test_loader)\n",
        "  return acc, running_loss\n",
        "\n",
        "train_dataset = MyDataset(transform,\"train\")\n",
        "test_dataset = MyDataset(transform,\"validation\")\n",
        "train_loader = DataLoader(train_dataset,batch_size=batch_size_train,shuffle=True)\n",
        "test_loader = DataLoader(test_dataset,batch_size=batch_size_test,shuffle=True)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer1 = optim.SGD(model1.parameters(),lr=lr)\n",
        "\n",
        "print(\"Without Dropout\")\n",
        "\n",
        "for epoch in range(1,epochs+1):\n",
        "  print(f\"Epoch: {epoch}\")\n",
        "  print(\"Training: \")\n",
        "  train_acc, train_loss = train(model1, train_loader, criterion, optimizer1, device)\n",
        "  print(\"\\tAccuracy: {:.4}%\".format(train_acc))\n",
        "  print(\"\\tLoss: {:.4}\".format(train_loss))\n",
        "\n",
        "  print(\"Validation: \")\n",
        "  test_acc, test_loss = test(model1, test_loader, criterion, device)\n",
        "  print(\"\\tAccuracy: {:.4}%\".format(test_acc))\n",
        "  print(\"\\tLoss: {:.4}\".format(test_loss))\n",
        "\n",
        "  no_dropout['train'].append(train_acc.item())\n",
        "  no_dropout['test'].append(test_acc.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PXSS1YrtK0n",
        "outputId": "ad2dc51a-3944-44a0-8a20-75835561a6f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "With Dropout\n",
            "Epoch: 1\n",
            "Training:\n",
            "\tAccuracy: 1491.80322265625%\n",
            "\tLoss: 2.603708149346172%\n",
            "Testing:\n",
            "\tAccuracy: 9530.0%\n",
            "\tLoss: 0.0012198191881179809%\n",
            "Epoch: 2\n",
            "Training:\n",
            "\tAccuracy: 1498.360595703125%\n",
            "\tLoss: 2.3430086227103333%\n",
            "Testing:\n",
            "\tAccuracy: 9520.0%\n",
            "\tLoss: 0.001258479818701744%\n",
            "Epoch: 3\n",
            "Training:\n",
            "\tAccuracy: 1517.2130126953125%\n",
            "\tLoss: 1.9669015815359403%\n",
            "Testing:\n",
            "\tAccuracy: 9500.0%\n",
            "\tLoss: 0.0012778423391282558%\n",
            "Epoch: 4\n",
            "Training:\n",
            "\tAccuracy: 1530.3277587890625%\n",
            "\tLoss: 1.6987318984064899%\n",
            "Testing:\n",
            "\tAccuracy: 9560.0%\n",
            "\tLoss: 0.0010391588024795055%\n",
            "Epoch: 5\n",
            "Training:\n",
            "\tAccuracy: 1537.704833984375%\n",
            "\tLoss: 1.3447108487159656%\n",
            "Testing:\n",
            "\tAccuracy: 9560.0%\n",
            "\tLoss: 0.0009538969695568085%\n",
            "Epoch: 6\n",
            "Training:\n",
            "\tAccuracy: 1547.5408935546875%\n",
            "\tLoss: 1.2356948857730041%\n",
            "Testing:\n",
            "\tAccuracy: 9480.0%\n",
            "\tLoss: 0.0011179698035120964%\n",
            "Epoch: 7\n",
            "Training:\n",
            "\tAccuracy: 1549.9998779296875%\n",
            "\tLoss: 1.1141316550860152%\n",
            "Testing:\n",
            "\tAccuracy: 8390.0%\n",
            "\tLoss: 0.005760994732379913%\n",
            "Epoch: 8\n",
            "Training:\n",
            "\tAccuracy: 1549.9998779296875%\n",
            "\tLoss: 1.1200068184789118%\n",
            "Testing:\n",
            "\tAccuracy: 9570.0%\n",
            "\tLoss: 0.0009549647755920887%\n",
            "Epoch: 9\n",
            "Training:\n",
            "\tAccuracy: 1559.016357421875%\n",
            "\tLoss: 0.8914213530704013%\n",
            "Testing:\n",
            "\tAccuracy: 9510.0%\n",
            "\tLoss: 0.0011274478808045386%\n",
            "Epoch: 10\n",
            "Training:\n",
            "\tAccuracy: 1558.1966552734375%\n",
            "\tLoss: 0.8403489943287904%\n",
            "Testing:\n",
            "\tAccuracy: 9590.0%\n",
            "\tLoss: 0.0009224099665880204%\n"
          ]
        }
      ],
      "source": [
        "print(\"With Dropout\")\n",
        "\n",
        "optimizer2 = optim.SGD(model2.parameters(),lr)\n",
        "for epoch in range(1,epochs+1):\n",
        "  print(\"Epoch:\",epoch)\n",
        "  print(\"Training:\")\n",
        "  train_acc, train_loss = train(model2,train_loader,criterion,optimizer2,device)\n",
        "  print(\"\\tAccuracy: {}%\".format(train_acc))\n",
        "  print(\"\\tLoss: {}%\".format(train_loss))\n",
        "  print(\"Testing:\")\n",
        "  test_acc, test_loss = test(model2,test_loader,criterion,device)\n",
        "  print(\"\\tAccuracy: {}%\".format(test_acc))\n",
        "  print(\"\\tLoss: {}%\".format(test_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkSpI-RzyLT-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
