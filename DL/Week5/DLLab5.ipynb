{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2451b503-8b08-4cea-ae6f-c82d7899d3dd",
   "metadata": {},
   "source": [
    "## Q1\n",
    "\n",
    "Implement convolution operation for a sample image of shape (H=6, W=6, C=1) with a\n",
    "random kernel of size (3,3) using torch.nn.functional.conv2d. \n",
    "\n",
    "What is the dimension of the output image? Apply, various values for parameter stride=1 and note the change in the dimension of the output image. Arrive at an equation for the output image size with respect to the kernel size and stride and verify your answer with code. Now, repeat the exercise by changing padding parameter. Obtain a formula using kernel, stride, and padding to get the output image size. What is the total number of parameters in your network? Verify with code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f63beb18-756e-4d29-8b0c-b9573e28f8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image= tensor([[0.1186, 0.7337, 0.9362, 0.6941, 0.9227, 0.1054],\n",
      "        [0.0437, 0.4127, 0.3661, 0.6174, 0.4510, 0.1018],\n",
      "        [0.0351, 0.9308, 0.9723, 0.7033, 0.8682, 0.1331],\n",
      "        [0.3270, 0.2197, 0.3275, 0.5457, 0.7827, 0.8512],\n",
      "        [0.8301, 0.7932, 0.5169, 0.0567, 0.7926, 0.9195],\n",
      "        [0.8814, 0.2048, 0.5625, 0.8749, 0.1683, 0.0961]])\n",
      "image.shape= torch.Size([1, 6, 6])\n",
      "image.shape= torch.Size([1, 1, 6, 6])\n",
      "image= tensor([[[[0.1186, 0.7337, 0.9362, 0.6941, 0.9227, 0.1054],\n",
      "          [0.0437, 0.4127, 0.3661, 0.6174, 0.4510, 0.1018],\n",
      "          [0.0351, 0.9308, 0.9723, 0.7033, 0.8682, 0.1331],\n",
      "          [0.3270, 0.2197, 0.3275, 0.5457, 0.7827, 0.8512],\n",
      "          [0.8301, 0.7932, 0.5169, 0.0567, 0.7926, 0.9195],\n",
      "          [0.8814, 0.2048, 0.5625, 0.8749, 0.1683, 0.0961]]]])\n",
      "kernel= tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "outimage= tensor([[[[4.5493, 6.3667, 6.5314, 4.5971],\n",
      "          [3.6350, 5.0957, 5.6344, 5.0546],\n",
      "          [4.9527, 5.0661, 5.5659, 5.6531],\n",
      "          [4.6631, 4.1019, 4.6277, 5.0876]]]])\n",
      "Dimension of output image S-1 P-0:  torch.Size([1, 1, 4, 4])\n",
      "Manually dim of output S-1 P-0:  [1, 1, 4, 4]\n",
      "Dimension of output image S-1 P-1: torch.Size([1, 1, 6, 6])\n",
      "Manually dim of output S-1 P-1:  [3, 3, 6, 6]\n",
      "Dimension of output image S-1 P-2: torch.Size([1, 1, 8, 8])\n",
      "Manually dim of output S-1 P-2:  [5, 5, 8, 8]\n",
      "Dimension of output image S-2 P-1:  torch.Size([1, 1, 3, 3])\n",
      "Manually dim of output S-2 P-1:  [2, 2, 3, 3]\n",
      "Dimension of output image S-2 P-1: torch.Size([1, 1, 2, 2])\n",
      "Manually dim of output S-3 P-1:  [1, 1, 2, 2]\n",
      "Number of Learnable Parameters = 9\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "image = torch.rand(6,6)\n",
    "print(\"image=\", image)\n",
    "#Add a new dimension along 0th dimension\n",
    "#i.e. (6,6) becomes (1,6,6). This is because\n",
    "#pytorch expects the input to conv2D as 4d tensor\n",
    "image = image.unsqueeze(dim=0)\n",
    "print(\"image.shape=\", image.shape)\n",
    "image = image.unsqueeze(dim=0)\n",
    "print(\"image.shape=\", image.shape)\n",
    "print(\"image=\", image)\n",
    "kernel = torch.ones(3,3)\n",
    "#kernel = torch.rand(3,3)\n",
    "print(\"kernel=\", kernel)\n",
    "kernel = kernel.unsqueeze(dim=0)\n",
    "kernel = kernel.unsqueeze(dim=0)\n",
    "\n",
    "def out_dim(in_shape,stride,padding,kernel_shape):\n",
    "    out_shape = [0 for i in range(4)]\n",
    "    for dim in range(len(in_shape)):\n",
    "        out_shape[dim] = (in_shape[dim] + 2*padding - kernel_shape[dim])//stride + 1\n",
    "    return out_shape\n",
    "    \n",
    "#Stride 1 Padding 0\n",
    "outimage = F.conv2d(image, kernel, stride=1, padding=0)\n",
    "print(\"outimage=\", outimage)\n",
    "print(\"Dimension of output image S-1 P-0: \",outimage.shape)\n",
    "print(\"Manually dim of output S-1 P-0: \",out_dim(image.shape,1,0,kernel.shape))\n",
    "\n",
    "#Stride 1 Padding 1\n",
    "outimage = F.conv2d(image, kernel, stride=1, padding=1)\n",
    "print(\"Dimension of output image S-1 P-1:\",outimage.shape)\n",
    "print(\"Manually dim of output S-1 P-1: \",out_dim(image.shape,1,1,kernel.shape))\n",
    "\n",
    "#Stride 1 Padding 2\n",
    "outimage = F.conv2d(image, kernel, stride=1, padding=2)\n",
    "print(\"Dimension of output image S-1 P-2:\",outimage.shape)\n",
    "print(\"Manually dim of output S-1 P-2: \",out_dim(image.shape,1,2,kernel.shape))\n",
    "\n",
    "#Stride 2 Padding 1\n",
    "outimage = F.conv2d(image, kernel, stride=2, padding=1)\n",
    "print(\"Dimension of output image S-2 P-1: \",outimage.shape)\n",
    "print(\"Manually dim of output S-2 P-1: \",out_dim(image.shape,2,1,kernel.shape))\n",
    "\n",
    "#Stride 3 Padding 1\n",
    "outimage = F.conv2d(image, kernel, stride=3, padding=1)\n",
    "print(\"Dimension of output image S-2 P-1:\",outimage.shape)\n",
    "print(\"Manually dim of output S-3 P-1: \",out_dim(image.shape,3,1,kernel.shape))\n",
    "\n",
    "print(\"Number of Learnable Parameters = 9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eced408-fccf-4442-8cb5-a40b2b86f7c6",
   "metadata": {},
   "source": [
    "## Q2 \n",
    "\n",
    "Apply torch.nn.Conv2d to the input image of Qn 1 with out-channel=3 and observe the\n",
    "output. Implement the equivalent of torch.nn.Conv2d using the torch.nn.functional.conv2D\n",
    "to get the same output. You may ignore bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "94b074b7-75ad-4ae6-bb2d-10f72b6a15d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel parameters for 3 channels: \n",
      "Parameter containing:\n",
      "tensor([[[[-0.0442, -0.0062,  0.1765],\n",
      "          [ 0.0043, -0.3088,  0.3210],\n",
      "          [ 0.1142, -0.2003, -0.3295]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2522, -0.1952,  0.2530],\n",
      "          [ 0.0576, -0.2026, -0.1792],\n",
      "          [-0.0216,  0.1752,  0.1663]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1334,  0.2059, -0.1624],\n",
      "          [ 0.0182, -0.1681,  0.0662],\n",
      "          [-0.0531, -0.0890, -0.0859]]]], requires_grad=True)\n",
      "Output image using torch.nn.Conv2d: \n",
      "tensor([[[[-0.3563, -0.1274, -0.2278, -0.2432],\n",
      "          [-0.0432, -0.1694, -0.3169, -0.1089],\n",
      "          [ 0.0831,  0.0602, -0.1804,  0.0947],\n",
      "          [-0.2690, -0.1873, -0.1555, -0.0782]],\n",
      "\n",
      "         [[ 0.0793,  0.3803,  0.1059,  0.0877],\n",
      "          [ 0.0911,  0.2746, -0.0041,  0.3246],\n",
      "          [ 0.2784, -0.0466,  0.0713,  0.2349],\n",
      "          [ 0.3512,  0.3800,  0.2487,  0.3445]],\n",
      "\n",
      "         [[-0.0861,  0.0829, -0.2119, -0.0823],\n",
      "          [ 0.1535, -0.2789, -0.1432, -0.0407],\n",
      "          [-0.0901, -0.0240,  0.0776, -0.0866],\n",
      "          [-0.1294, -0.1112, -0.0775, -0.1246]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "Output image using torch.nn.functional.conv2d: \n",
      "tensor([[[[-0.3563, -0.1274, -0.2278, -0.2432],\n",
      "          [-0.0432, -0.1694, -0.3169, -0.1089],\n",
      "          [ 0.0831,  0.0602, -0.1804,  0.0947],\n",
      "          [-0.2690, -0.1873, -0.1555, -0.0782]],\n",
      "\n",
      "         [[ 0.0793,  0.3803,  0.1059,  0.0877],\n",
      "          [ 0.0911,  0.2746, -0.0041,  0.3246],\n",
      "          [ 0.2784, -0.0466,  0.0713,  0.2349],\n",
      "          [ 0.3512,  0.3800,  0.2487,  0.3445]],\n",
      "\n",
      "         [[-0.0861,  0.0829, -0.2119, -0.0823],\n",
      "          [ 0.1535, -0.2789, -0.1432, -0.0407],\n",
      "          [-0.0901, -0.0240,  0.0776, -0.0866],\n",
      "          [-0.1294, -0.1112, -0.0775, -0.1246]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "image= torch.tensor([[[[0.2557, 0.9236, 0.4913, 0.3200, 0.4958, 0.2214],\n",
    "          [0.7554, 0.6501, 0.0107, 0.8675, 0.5163, 0.6102],\n",
    "          [0.8228, 0.1919, 0.8724, 0.8043, 0.3882, 0.9689],\n",
    "          [0.4894, 0.5116, 0.5624, 0.6949, 0.6289, 0.9802],\n",
    "          [0.3913, 0.2773, 0.1427, 0.3717, 0.4154, 0.3669],\n",
    "          [0.8327, 0.8157, 0.7192, 0.9387, 0.4569, 0.6776]]]])\n",
    "\n",
    "conv = nn.Conv2d(in_channels=1,out_channels=3,kernel_size=3,stride=1,padding=0,bias=False)\n",
    "print(\"Kernel parameters for 3 channels: \")\n",
    "kernel = conv.weight\n",
    "print(conv.weight)\n",
    "print(\"Output image using torch.nn.Conv2d: \")\n",
    "out_image = print(conv(image))\n",
    "\n",
    "import torch.nn.functional as F\n",
    "out_image = F.conv2d(image,kernel,stride=1,padding=0)\n",
    "print(\"Output image using torch.nn.functional.conv2d: \")\n",
    "print(out_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e426921-6471-48ed-b498-9017accd3932",
   "metadata": {},
   "source": [
    "## Q3 \n",
    "\n",
    "Implement CNN for classifying digits in MNIST dataset using PyTorch. Display the classification accuracy in the form of a Confusion matrix. Verify the number of learnable parameters in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ffe4dd0e-3792-417b-ab9c-c356feefb3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.310\n",
      "[1,   200] loss: 2.297\n",
      "[1,   300] loss: 2.285\n",
      "[1,   400] loss: 2.272\n",
      "[1,   500] loss: 2.249\n",
      "[1,   600] loss: 2.198\n",
      "[1,   700] loss: 2.087\n",
      "[1,   800] loss: 1.823\n",
      "[1,   900] loss: 1.423\n",
      "[1,  1000] loss: 1.160\n",
      "[1,  1100] loss: 0.925\n",
      "[1,  1200] loss: 0.799\n",
      "[2,   100] loss: 0.698\n",
      "[2,   200] loss: 0.603\n",
      "[2,   300] loss: 0.542\n",
      "[2,   400] loss: 0.474\n",
      "[2,   500] loss: 0.442\n",
      "[2,   600] loss: 0.414\n",
      "[2,   700] loss: 0.365\n",
      "[2,   800] loss: 0.330\n",
      "[2,   900] loss: 0.317\n",
      "[2,  1000] loss: 0.311\n",
      "[2,  1100] loss: 0.297\n",
      "[2,  1200] loss: 0.294\n",
      "[3,   100] loss: 0.271\n",
      "[3,   200] loss: 0.261\n",
      "[3,   300] loss: 0.250\n",
      "[3,   400] loss: 0.258\n",
      "[3,   500] loss: 0.228\n",
      "[3,   600] loss: 0.231\n",
      "[3,   700] loss: 0.220\n",
      "[3,   800] loss: 0.209\n",
      "[3,   900] loss: 0.192\n",
      "[3,  1000] loss: 0.210\n",
      "[3,  1100] loss: 0.225\n",
      "[3,  1200] loss: 0.189\n",
      "[4,   100] loss: 0.187\n",
      "[4,   200] loss: 0.183\n",
      "[4,   300] loss: 0.187\n",
      "[4,   400] loss: 0.164\n",
      "[4,   500] loss: 0.182\n",
      "[4,   600] loss: 0.189\n",
      "[4,   700] loss: 0.170\n",
      "[4,   800] loss: 0.155\n",
      "[4,   900] loss: 0.163\n",
      "[4,  1000] loss: 0.172\n",
      "[4,  1100] loss: 0.160\n",
      "[4,  1200] loss: 0.157\n",
      "[5,   100] loss: 0.147\n",
      "[5,   200] loss: 0.149\n",
      "[5,   300] loss: 0.146\n",
      "[5,   400] loss: 0.155\n",
      "[5,   500] loss: 0.155\n",
      "[5,   600] loss: 0.131\n",
      "[5,   700] loss: 0.141\n",
      "[5,   800] loss: 0.130\n",
      "[5,   900] loss: 0.136\n",
      "[5,  1000] loss: 0.130\n",
      "[5,  1100] loss: 0.140\n",
      "[5,  1200] loss: 0.134\n",
      "[6,   100] loss: 0.131\n",
      "[6,   200] loss: 0.130\n",
      "[6,   300] loss: 0.121\n",
      "[6,   400] loss: 0.131\n",
      "[6,   500] loss: 0.119\n",
      "[6,   600] loss: 0.121\n",
      "[6,   700] loss: 0.124\n",
      "[6,   800] loss: 0.123\n",
      "[6,   900] loss: 0.114\n",
      "[6,  1000] loss: 0.118\n",
      "[6,  1100] loss: 0.113\n",
      "[6,  1200] loss: 0.107\n",
      "Finished Training. Final loss = 0.08542836457490921, Total params = 149798\n",
      "Correct = 9710, Total = 10000\n",
      "[955, 0, 3, 0, 1, 3, 5, 1, 3, 3]\n",
      "[1, 1129, 4, 0, 3, 0, 3, 7, 2, 5]\n",
      "[3, 2, 996, 9, 4, 1, 0, 18, 2, 0]\n",
      "[0, 1, 2, 970, 0, 3, 0, 0, 2, 1]\n",
      "[2, 0, 0, 0, 959, 0, 4, 0, 2, 12]\n",
      "[4, 0, 1, 12, 0, 873, 8, 1, 4, 9]\n",
      "[11, 2, 2, 0, 5, 3, 935, 0, 7, 1]\n",
      "[2, 0, 18, 10, 1, 2, 0, 992, 5, 6]\n",
      "[2, 1, 5, 7, 3, 7, 3, 2, 942, 13]\n",
      "[0, 0, 1, 2, 6, 0, 0, 7, 5, 959]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transform\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(1,64,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(64,128,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(128,64,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                )\n",
    "        self.classification_head = nn.Sequential(nn.Linear(64,20,bias=True),\n",
    "                                                 nn.ReLU(),\n",
    "                                                 nn.Linear(20,10,bias=True),)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        features = self.net(x)\n",
    "        return self.classification_head(features.view(batch_size,-1))\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root=\"./data\",download = True,train=True,transform=ToTensor())\n",
    "train_loader = DataLoader(mnist_trainset,batch_size=50,shuffle=True)\n",
    "mnist_testset = datasets.MNIST(root=\"./data\",download = True,train=False,transform=ToTensor())\n",
    "test_loader = DataLoader(mnist_testset,batch_size=50,shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNClassifier().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "batch_size=50\n",
    "\n",
    "total_params = 0\n",
    "for name,param in model.named_parameters():\n",
    "    params = param.numel()\n",
    "    total_params += params\n",
    "\n",
    "for epoch in range(6):  \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  \n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(f\"Finished Training. Final loss = {loss.item()}, Total params = {total_params}\")\n",
    "\n",
    "correct,total = 0,0\n",
    "for i,vdata in enumerate(test_loader):\n",
    "    tinputs,tlabels = vdata[0].to(device), vdata[1].to(device)\n",
    "    toutputs = model(tinputs)\n",
    "\n",
    "    _,predicted = torch.max(toutputs,1)\n",
    "    total += tlabels.size(0)\n",
    "    correct += (predicted==tlabels).sum()\n",
    "        \n",
    "print(f\"Correct = {correct}, Total = {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca5a7d9-ed64-4d1d-ab72-ed8c580a6cc9",
   "metadata": {},
   "source": [
    "## Q4\n",
    "\n",
    "Modify CNN of Qn. 3 to reduce the number of parameters in the network. Draw a plot of\n",
    "percentage drop in parameters vs accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c50ee7e0-4821-4662-ad21-4f671aa6744b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.304\n",
      "[1,   200] loss: 2.294\n",
      "[1,   300] loss: 2.289\n",
      "[1,   400] loss: 2.277\n",
      "[1,   500] loss: 2.259\n",
      "[1,   600] loss: 2.223\n",
      "[1,   700] loss: 2.154\n",
      "[1,   800] loss: 1.979\n",
      "[1,   900] loss: 1.609\n",
      "[1,  1000] loss: 1.187\n",
      "[1,  1100] loss: 0.967\n",
      "[1,  1200] loss: 0.823\n",
      "[2,   100] loss: 0.768\n",
      "[2,   200] loss: 0.636\n",
      "[2,   300] loss: 0.591\n",
      "[2,   400] loss: 0.517\n",
      "[2,   500] loss: 0.480\n",
      "[2,   600] loss: 0.468\n",
      "[2,   700] loss: 0.434\n",
      "[2,   800] loss: 0.423\n",
      "[2,   900] loss: 0.386\n",
      "[2,  1000] loss: 0.374\n",
      "[2,  1100] loss: 0.369\n",
      "[2,  1200] loss: 0.367\n",
      "[3,   100] loss: 0.328\n",
      "[3,   200] loss: 0.341\n",
      "[3,   300] loss: 0.319\n",
      "[3,   400] loss: 0.295\n",
      "[3,   500] loss: 0.295\n",
      "[3,   600] loss: 0.285\n",
      "[3,   700] loss: 0.286\n",
      "[3,   800] loss: 0.284\n",
      "[3,   900] loss: 0.276\n",
      "[3,  1000] loss: 0.283\n",
      "[3,  1100] loss: 0.268\n",
      "[3,  1200] loss: 0.243\n",
      "[4,   100] loss: 0.256\n",
      "[4,   200] loss: 0.236\n",
      "[4,   300] loss: 0.266\n",
      "[4,   400] loss: 0.212\n",
      "[4,   500] loss: 0.251\n",
      "[4,   600] loss: 0.215\n",
      "[4,   700] loss: 0.231\n",
      "[4,   800] loss: 0.234\n",
      "[4,   900] loss: 0.225\n",
      "[4,  1000] loss: 0.195\n",
      "[4,  1100] loss: 0.219\n",
      "[4,  1200] loss: 0.209\n",
      "[5,   100] loss: 0.194\n",
      "[5,   200] loss: 0.215\n",
      "[5,   300] loss: 0.213\n",
      "[5,   400] loss: 0.209\n",
      "[5,   500] loss: 0.183\n",
      "[5,   600] loss: 0.191\n",
      "[5,   700] loss: 0.205\n",
      "[5,   800] loss: 0.203\n",
      "[5,   900] loss: 0.184\n",
      "[5,  1000] loss: 0.175\n",
      "[5,  1100] loss: 0.191\n",
      "[5,  1200] loss: 0.167\n",
      "[6,   100] loss: 0.176\n",
      "[6,   200] loss: 0.174\n",
      "[6,   300] loss: 0.175\n",
      "[6,   400] loss: 0.165\n",
      "[6,   500] loss: 0.183\n",
      "[6,   600] loss: 0.153\n",
      "[6,   700] loss: 0.178\n",
      "[6,   800] loss: 0.167\n",
      "[6,   900] loss: 0.172\n",
      "[6,  1000] loss: 0.170\n",
      "[6,  1100] loss: 0.153\n",
      "[6,  1200] loss: 0.168\n",
      "Finished Training. Final loss = 0.07159193605184555, Total params = 9594\n",
      "Correct = 9531, Total = 10000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transform\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class CNNClassifier1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(1,16,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(16,32,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(32,16,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                )\n",
    "        self.classification_head = nn.Sequential(nn.Linear(16,10,bias=True),)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        features = self.net(x)\n",
    "        return self.classification_head(features.view(batch_size,-1))\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root=\"./data\",download = True,train=True,transform=ToTensor())\n",
    "train_loader = DataLoader(mnist_trainset,batch_size=50,shuffle=True)\n",
    "mnist_testset = datasets.MNIST(root=\"./data\",download = True,train=False,transform=ToTensor())\n",
    "test_loader = DataLoader(mnist_testset,batch_size=50,shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model1 = CNNClassifier1().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model1.parameters(), lr=0.01)\n",
    "batch_size=50\n",
    "\n",
    "total_params = 0\n",
    "for name,param in model1.named_parameters():\n",
    "    params = param.numel()\n",
    "    total_params += params\n",
    "\n",
    "for epoch in range(6):  \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model1(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  \n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(f\"Finished Training. Final loss = {loss.item()}, Total params = {total_params}\")\n",
    "\n",
    "correct,total = 0,0\n",
    "for i,vdata in enumerate(test_loader):\n",
    "    tinputs,tlabels = vdata[0].to(device), vdata[1].to(device)\n",
    "    toutputs = model1(tinputs)\n",
    "\n",
    "    _,predicted = torch.max(toutputs,1)\n",
    "    total += tlabels.size(0)\n",
    "    correct += (predicted==tlabels).sum()\n",
    "        \n",
    "print(f\"Correct = {correct}, Total = {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9c000d6-9bbc-4796-bf88-f31189c20dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.310\n",
      "[1,   200] loss: 2.305\n",
      "[1,   300] loss: 2.300\n",
      "[1,   400] loss: 2.298\n",
      "[1,   500] loss: 2.293\n",
      "[1,   600] loss: 2.289\n",
      "[1,   700] loss: 2.281\n",
      "[1,   800] loss: 2.270\n",
      "[1,   900] loss: 2.251\n",
      "[1,  1000] loss: 2.209\n",
      "[1,  1100] loss: 2.121\n",
      "[1,  1200] loss: 1.938\n",
      "[2,   100] loss: 1.663\n",
      "[2,   200] loss: 1.413\n",
      "[2,   300] loss: 1.158\n",
      "[2,   400] loss: 0.963\n",
      "[2,   500] loss: 0.842\n",
      "[2,   600] loss: 0.694\n",
      "[2,   700] loss: 0.601\n",
      "[2,   800] loss: 0.546\n",
      "[2,   900] loss: 0.471\n",
      "[2,  1000] loss: 0.427\n",
      "[2,  1100] loss: 0.408\n",
      "[2,  1200] loss: 0.381\n",
      "[3,   100] loss: 0.359\n",
      "[3,   200] loss: 0.318\n",
      "[3,   300] loss: 0.313\n",
      "[3,   400] loss: 0.297\n",
      "[3,   500] loss: 0.277\n",
      "[3,   600] loss: 0.285\n",
      "[3,   700] loss: 0.257\n",
      "[3,   800] loss: 0.243\n",
      "[3,   900] loss: 0.223\n",
      "[3,  1000] loss: 0.252\n",
      "[3,  1100] loss: 0.238\n",
      "[3,  1200] loss: 0.229\n",
      "[4,   100] loss: 0.217\n",
      "[4,   200] loss: 0.208\n",
      "[4,   300] loss: 0.231\n",
      "[4,   400] loss: 0.195\n",
      "[4,   500] loss: 0.194\n",
      "[4,   600] loss: 0.214\n",
      "[4,   700] loss: 0.177\n",
      "[4,   800] loss: 0.194\n",
      "[4,   900] loss: 0.181\n",
      "[4,  1000] loss: 0.178\n",
      "[4,  1100] loss: 0.171\n",
      "[4,  1200] loss: 0.172\n",
      "[5,   100] loss: 0.172\n",
      "[5,   200] loss: 0.166\n",
      "[5,   300] loss: 0.168\n",
      "[5,   400] loss: 0.154\n",
      "[5,   500] loss: 0.155\n",
      "[5,   600] loss: 0.165\n",
      "[5,   700] loss: 0.158\n",
      "[5,   800] loss: 0.157\n",
      "[5,   900] loss: 0.142\n",
      "[5,  1000] loss: 0.159\n",
      "[5,  1100] loss: 0.161\n",
      "[5,  1200] loss: 0.133\n",
      "[6,   100] loss: 0.161\n",
      "[6,   200] loss: 0.141\n",
      "[6,   300] loss: 0.149\n",
      "[6,   400] loss: 0.131\n",
      "[6,   500] loss: 0.144\n",
      "[6,   600] loss: 0.137\n",
      "[6,   700] loss: 0.121\n",
      "[6,   800] loss: 0.127\n",
      "[6,   900] loss: 0.133\n",
      "[6,  1000] loss: 0.130\n",
      "[6,  1100] loss: 0.117\n",
      "[6,  1200] loss: 0.128\n",
      "Finished Training. Final loss = 0.2579786479473114, Total params = 38150\n",
      "[1,   100] loss: 2.303\n",
      "[1,   200] loss: 2.300\n",
      "[1,   300] loss: 2.295\n",
      "[1,   400] loss: 2.292\n",
      "[1,   500] loss: 2.288\n",
      "[1,   600] loss: 2.278\n",
      "[1,   700] loss: 2.267\n",
      "[1,   800] loss: 2.245\n",
      "[1,   900] loss: 2.198\n",
      "[1,  1000] loss: 2.097\n",
      "[1,  1100] loss: 1.952\n",
      "[1,  1200] loss: 1.809\n",
      "[2,   100] loss: 1.676\n",
      "[2,   200] loss: 1.588\n",
      "[2,   300] loss: 1.453\n",
      "[2,   400] loss: 1.226\n",
      "[2,   500] loss: 1.036\n",
      "[2,   600] loss: 0.859\n",
      "[2,   700] loss: 0.686\n",
      "[2,   800] loss: 0.616\n",
      "[2,   900] loss: 0.522\n",
      "[2,  1000] loss: 0.466\n",
      "[2,  1100] loss: 0.419\n",
      "[2,  1200] loss: 0.395\n",
      "[3,   100] loss: 0.341\n",
      "[3,   200] loss: 0.323\n",
      "[3,   300] loss: 0.292\n",
      "[3,   400] loss: 0.291\n",
      "[3,   500] loss: 0.277\n",
      "[3,   600] loss: 0.280\n",
      "[3,   700] loss: 0.242\n",
      "[3,   800] loss: 0.229\n",
      "[3,   900] loss: 0.231\n",
      "[3,  1000] loss: 0.239\n",
      "[3,  1100] loss: 0.222\n",
      "[3,  1200] loss: 0.216\n",
      "[4,   100] loss: 0.191\n",
      "[4,   200] loss: 0.215\n",
      "[4,   300] loss: 0.172\n",
      "[4,   400] loss: 0.181\n",
      "[4,   500] loss: 0.178\n",
      "[4,   600] loss: 0.179\n",
      "[4,   700] loss: 0.166\n",
      "[4,   800] loss: 0.158\n",
      "[4,   900] loss: 0.169\n",
      "[4,  1000] loss: 0.161\n",
      "[4,  1100] loss: 0.178\n",
      "[4,  1200] loss: 0.144\n",
      "[5,   100] loss: 0.158\n",
      "[5,   200] loss: 0.128\n",
      "[5,   300] loss: 0.143\n",
      "[5,   400] loss: 0.143\n",
      "[5,   500] loss: 0.140\n",
      "[5,   600] loss: 0.145\n",
      "[5,   700] loss: 0.128\n",
      "[5,   800] loss: 0.141\n",
      "[5,   900] loss: 0.138\n",
      "[5,  1000] loss: 0.117\n",
      "[5,  1100] loss: 0.120\n",
      "[5,  1200] loss: 0.131\n",
      "[6,   100] loss: 0.124\n",
      "[6,   200] loss: 0.108\n",
      "[6,   300] loss: 0.113\n",
      "[6,   400] loss: 0.114\n",
      "[6,   500] loss: 0.121\n",
      "[6,   600] loss: 0.128\n",
      "[6,   700] loss: 0.098\n",
      "[6,   800] loss: 0.112\n",
      "[6,   900] loss: 0.097\n",
      "[6,  1000] loss: 0.116\n",
      "[6,  1100] loss: 0.110\n",
      "[6,  1200] loss: 0.112\n",
      "Finished Training. Final loss = 0.055033281445503235, Total params = 601254\n"
     ]
    }
   ],
   "source": [
    "class CNNClassifier2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(1,32,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(32,64,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(64,32,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                )\n",
    "        self.classification_head = nn.Sequential(nn.Linear(32,20,bias=True),\n",
    "                                                 nn.ReLU(),\n",
    "                                                 nn.Linear(20,10,bias=True),)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        features = self.net(x)\n",
    "        return self.classification_head(features.view(batch_size,-1))\n",
    "\n",
    "class CNNClassifier3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(1,128,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(128,256,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(256,128,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                )\n",
    "        self.classification_head = nn.Sequential(nn.Linear(128,64,bias=True),\n",
    "                                                 nn.ReLU(),\n",
    "                                                 nn.Linear(64,20,bias=True),\n",
    "                                                 nn.ReLU(),\n",
    "                                                 nn.Linear(20,10,bias=True),)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        features = self.net(x)\n",
    "        return self.classification_head(features.view(batch_size,-1))\n",
    "\n",
    "model2 = CNNClassifier2().to(device)\n",
    "optimizer = optim.SGD(model2.parameters(), lr=0.01)\n",
    "batch_size=50\n",
    "model3 = CNNClassifier3().to(device)\n",
    "loss = None\n",
    "total_params = 0\n",
    "for name,param in model2.named_parameters():\n",
    "    params = param.numel()\n",
    "    total_params += params\n",
    "\n",
    "for epoch in range(6):  \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model2(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  \n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(f\"Finished Training. Final loss = {loss.item()}, Total params = {total_params}\")\n",
    "\n",
    "loss = None\n",
    "optimizer = optim.SGD(model3.parameters(), lr=0.01)\n",
    "batch_size=50\n",
    "\n",
    "total_params = 0\n",
    "for name,param in model3.named_parameters():\n",
    "    params = param.numel()\n",
    "    total_params += params\n",
    "\n",
    "for epoch in range(6):  \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model3(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  \n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(f\"Finished Training. Final loss = {loss.item()}, Total params = {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfeb891a-6f7a-4bf5-b9e2-5898f7f63ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcbd5d21ad0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = [0.055033281445503235,0.08542836457490921,0.2579786479473114,0.07159193605184555]\n",
    "params = [601254,149798,38150,9594]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(params,losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0587c0-b4d4-476a-8b7c-d9e6a528346a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
