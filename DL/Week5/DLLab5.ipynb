{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2451b503-8b08-4cea-ae6f-c82d7899d3dd",
   "metadata": {},
   "source": [
    "## Q1\n",
    "\n",
    "Implement convolution operation for a sample image of shape (H=6, W=6, C=1) with a\n",
    "random kernel of size (3,3) using torch.nn.functional.conv2d. \n",
    "\n",
    "What is the dimension of the output image? Apply, various values for parameter stride=1 and note the change in the dimension of the output image. Arrive at an equation for the output image size with respect to the kernel size and stride and verify your answer with code. Now, repeat the exercise by changing padding parameter. Obtain a formula using kernel, stride, and padding to get the output image size. What is the total number of parameters in your network? Verify with code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f63beb18-756e-4d29-8b0c-b9573e28f8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image= tensor([[0.1186, 0.7337, 0.9362, 0.6941, 0.9227, 0.1054],\n",
      "        [0.0437, 0.4127, 0.3661, 0.6174, 0.4510, 0.1018],\n",
      "        [0.0351, 0.9308, 0.9723, 0.7033, 0.8682, 0.1331],\n",
      "        [0.3270, 0.2197, 0.3275, 0.5457, 0.7827, 0.8512],\n",
      "        [0.8301, 0.7932, 0.5169, 0.0567, 0.7926, 0.9195],\n",
      "        [0.8814, 0.2048, 0.5625, 0.8749, 0.1683, 0.0961]])\n",
      "image.shape= torch.Size([1, 6, 6])\n",
      "image.shape= torch.Size([1, 1, 6, 6])\n",
      "image= tensor([[[[0.1186, 0.7337, 0.9362, 0.6941, 0.9227, 0.1054],\n",
      "          [0.0437, 0.4127, 0.3661, 0.6174, 0.4510, 0.1018],\n",
      "          [0.0351, 0.9308, 0.9723, 0.7033, 0.8682, 0.1331],\n",
      "          [0.3270, 0.2197, 0.3275, 0.5457, 0.7827, 0.8512],\n",
      "          [0.8301, 0.7932, 0.5169, 0.0567, 0.7926, 0.9195],\n",
      "          [0.8814, 0.2048, 0.5625, 0.8749, 0.1683, 0.0961]]]])\n",
      "kernel= tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "outimage= tensor([[[[4.5493, 6.3667, 6.5314, 4.5971],\n",
      "          [3.6350, 5.0957, 5.6344, 5.0546],\n",
      "          [4.9527, 5.0661, 5.5659, 5.6531],\n",
      "          [4.6631, 4.1019, 4.6277, 5.0876]]]])\n",
      "Dimension of output image S-1 P-0:  torch.Size([1, 1, 4, 4])\n",
      "Manually dim of output S-1 P-0:  [1, 1, 4, 4]\n",
      "Dimension of output image S-1 P-1: torch.Size([1, 1, 6, 6])\n",
      "Manually dim of output S-1 P-1:  [3, 3, 6, 6]\n",
      "Dimension of output image S-1 P-2: torch.Size([1, 1, 8, 8])\n",
      "Manually dim of output S-1 P-2:  [5, 5, 8, 8]\n",
      "Dimension of output image S-2 P-1:  torch.Size([1, 1, 3, 3])\n",
      "Manually dim of output S-2 P-1:  [2, 2, 3, 3]\n",
      "Dimension of output image S-2 P-1: torch.Size([1, 1, 2, 2])\n",
      "Manually dim of output S-3 P-1:  [1, 1, 2, 2]\n",
      "Number of Learnable Parameters = 9\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "image = torch.rand(6,6)\n",
    "print(\"image=\", image)\n",
    "#Add a new dimension along 0th dimension\n",
    "#i.e. (6,6) becomes (1,6,6). This is because\n",
    "#pytorch expects the input to conv2D as 4d tensor\n",
    "image = image.unsqueeze(dim=0)\n",
    "print(\"image.shape=\", image.shape)\n",
    "image = image.unsqueeze(dim=0)\n",
    "print(\"image.shape=\", image.shape)\n",
    "print(\"image=\", image)\n",
    "kernel = torch.ones(3,3)\n",
    "#kernel = torch.rand(3,3)\n",
    "print(\"kernel=\", kernel)\n",
    "kernel = kernel.unsqueeze(dim=0)\n",
    "kernel = kernel.unsqueeze(dim=0)\n",
    "\n",
    "def out_dim(in_shape,stride,padding,kernel_shape):\n",
    "    out_shape = [0 for i in range(4)]\n",
    "    for dim in range(len(in_shape)):\n",
    "        out_shape[dim] = (in_shape[dim] + 2*padding - kernel_shape[dim])//stride + 1\n",
    "    return out_shape\n",
    "    \n",
    "#Stride 1 Padding 0\n",
    "outimage = F.conv2d(image, kernel, stride=1, padding=0)\n",
    "print(\"outimage=\", outimage)\n",
    "print(\"Dimension of output image S-1 P-0: \",outimage.shape)\n",
    "print(\"Manually dim of output S-1 P-0: \",out_dim(image.shape,1,0,kernel.shape))\n",
    "\n",
    "#Stride 1 Padding 1\n",
    "outimage = F.conv2d(image, kernel, stride=1, padding=1)\n",
    "print(\"Dimension of output image S-1 P-1:\",outimage.shape)\n",
    "print(\"Manually dim of output S-1 P-1: \",out_dim(image.shape,1,1,kernel.shape))\n",
    "\n",
    "#Stride 1 Padding 2\n",
    "outimage = F.conv2d(image, kernel, stride=1, padding=2)\n",
    "print(\"Dimension of output image S-1 P-2:\",outimage.shape)\n",
    "print(\"Manually dim of output S-1 P-2: \",out_dim(image.shape,1,2,kernel.shape))\n",
    "\n",
    "#Stride 2 Padding 1\n",
    "outimage = F.conv2d(image, kernel, stride=2, padding=1)\n",
    "print(\"Dimension of output image S-2 P-1: \",outimage.shape)\n",
    "print(\"Manually dim of output S-2 P-1: \",out_dim(image.shape,2,1,kernel.shape))\n",
    "\n",
    "#Stride 3 Padding 1\n",
    "outimage = F.conv2d(image, kernel, stride=3, padding=1)\n",
    "print(\"Dimension of output image S-2 P-1:\",outimage.shape)\n",
    "print(\"Manually dim of output S-3 P-1: \",out_dim(image.shape,3,1,kernel.shape))\n",
    "\n",
    "print(\"Number of Learnable Parameters = 9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eced408-fccf-4442-8cb5-a40b2b86f7c6",
   "metadata": {},
   "source": [
    "## Q2 \n",
    "\n",
    "Apply torch.nn.Conv2d to the input image of Qn 1 with out-channel=3 and observe the\n",
    "output. Implement the equivalent of torch.nn.Conv2d using the torch.nn.functional.conv2D\n",
    "to get the same output. You may ignore bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "94b074b7-75ad-4ae6-bb2d-10f72b6a15d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel parameters for 3 channels: \n",
      "Parameter containing:\n",
      "tensor([[[[-0.0442, -0.0062,  0.1765],\n",
      "          [ 0.0043, -0.3088,  0.3210],\n",
      "          [ 0.1142, -0.2003, -0.3295]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2522, -0.1952,  0.2530],\n",
      "          [ 0.0576, -0.2026, -0.1792],\n",
      "          [-0.0216,  0.1752,  0.1663]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1334,  0.2059, -0.1624],\n",
      "          [ 0.0182, -0.1681,  0.0662],\n",
      "          [-0.0531, -0.0890, -0.0859]]]], requires_grad=True)\n",
      "Output image using torch.nn.Conv2d: \n",
      "tensor([[[[-0.3563, -0.1274, -0.2278, -0.2432],\n",
      "          [-0.0432, -0.1694, -0.3169, -0.1089],\n",
      "          [ 0.0831,  0.0602, -0.1804,  0.0947],\n",
      "          [-0.2690, -0.1873, -0.1555, -0.0782]],\n",
      "\n",
      "         [[ 0.0793,  0.3803,  0.1059,  0.0877],\n",
      "          [ 0.0911,  0.2746, -0.0041,  0.3246],\n",
      "          [ 0.2784, -0.0466,  0.0713,  0.2349],\n",
      "          [ 0.3512,  0.3800,  0.2487,  0.3445]],\n",
      "\n",
      "         [[-0.0861,  0.0829, -0.2119, -0.0823],\n",
      "          [ 0.1535, -0.2789, -0.1432, -0.0407],\n",
      "          [-0.0901, -0.0240,  0.0776, -0.0866],\n",
      "          [-0.1294, -0.1112, -0.0775, -0.1246]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "Output image using torch.nn.functional.conv2d: \n",
      "tensor([[[[-0.3563, -0.1274, -0.2278, -0.2432],\n",
      "          [-0.0432, -0.1694, -0.3169, -0.1089],\n",
      "          [ 0.0831,  0.0602, -0.1804,  0.0947],\n",
      "          [-0.2690, -0.1873, -0.1555, -0.0782]],\n",
      "\n",
      "         [[ 0.0793,  0.3803,  0.1059,  0.0877],\n",
      "          [ 0.0911,  0.2746, -0.0041,  0.3246],\n",
      "          [ 0.2784, -0.0466,  0.0713,  0.2349],\n",
      "          [ 0.3512,  0.3800,  0.2487,  0.3445]],\n",
      "\n",
      "         [[-0.0861,  0.0829, -0.2119, -0.0823],\n",
      "          [ 0.1535, -0.2789, -0.1432, -0.0407],\n",
      "          [-0.0901, -0.0240,  0.0776, -0.0866],\n",
      "          [-0.1294, -0.1112, -0.0775, -0.1246]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "image= torch.tensor([[[[0.2557, 0.9236, 0.4913, 0.3200, 0.4958, 0.2214],\n",
    "          [0.7554, 0.6501, 0.0107, 0.8675, 0.5163, 0.6102],\n",
    "          [0.8228, 0.1919, 0.8724, 0.8043, 0.3882, 0.9689],\n",
    "          [0.4894, 0.5116, 0.5624, 0.6949, 0.6289, 0.9802],\n",
    "          [0.3913, 0.2773, 0.1427, 0.3717, 0.4154, 0.3669],\n",
    "          [0.8327, 0.8157, 0.7192, 0.9387, 0.4569, 0.6776]]]])\n",
    "\n",
    "conv = nn.Conv2d(in_channels=1,out_channels=3,kernel_size=3,stride=1,padding=0,bias=False)\n",
    "print(\"Kernel parameters for 3 channels: \")\n",
    "kernel = conv.weight\n",
    "print(conv.weight)\n",
    "print(\"Output image using torch.nn.Conv2d: \")\n",
    "out_image = print(conv(image))\n",
    "\n",
    "import torch.nn.functional as F\n",
    "out_image = F.conv2d(image,kernel,stride=1,padding=0)\n",
    "print(\"Output image using torch.nn.functional.conv2d: \")\n",
    "print(out_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e426921-6471-48ed-b498-9017accd3932",
   "metadata": {},
   "source": [
    "## Q3 \n",
    "\n",
    "Implement CNN for classifying digits in MNIST dataset using PyTorch. Display the classification accuracy in the form of a Confusion matrix. Verify the number of learnable parameters in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffe4dd0e-3792-417b-ab9c-c356feefb3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.313\n",
      "[1,   200] loss: 2.301\n",
      "[1,   300] loss: 2.291\n",
      "[1,   400] loss: 2.278\n",
      "[1,   500] loss: 2.259\n",
      "[1,   600] loss: 2.221\n",
      "[1,   700] loss: 2.145\n",
      "[1,   800] loss: 1.973\n",
      "[1,   900] loss: 1.635\n",
      "[1,  1000] loss: 1.279\n",
      "[1,  1100] loss: 1.000\n",
      "[1,  1200] loss: 0.809\n",
      "[2,   100] loss: 0.721\n",
      "[2,   200] loss: 0.619\n",
      "[2,   300] loss: 0.535\n",
      "[2,   400] loss: 0.496\n",
      "[2,   500] loss: 0.429\n",
      "[2,   600] loss: 0.412\n",
      "[2,   700] loss: 0.364\n",
      "[2,   800] loss: 0.332\n",
      "[2,   900] loss: 0.314\n",
      "[2,  1000] loss: 0.303\n",
      "[2,  1100] loss: 0.302\n",
      "[2,  1200] loss: 0.296\n",
      "[3,   100] loss: 0.247\n",
      "[3,   200] loss: 0.259\n",
      "[3,   300] loss: 0.252\n",
      "[3,   400] loss: 0.242\n",
      "[3,   500] loss: 0.234\n",
      "[3,   600] loss: 0.220\n",
      "[3,   700] loss: 0.226\n",
      "[3,   800] loss: 0.209\n",
      "[3,   900] loss: 0.226\n",
      "[3,  1000] loss: 0.208\n",
      "[3,  1100] loss: 0.206\n",
      "[3,  1200] loss: 0.188\n",
      "[4,   100] loss: 0.187\n",
      "[4,   200] loss: 0.184\n",
      "[4,   300] loss: 0.179\n",
      "[4,   400] loss: 0.178\n",
      "[4,   500] loss: 0.179\n",
      "[4,   600] loss: 0.177\n",
      "[4,   700] loss: 0.171\n",
      "[4,   800] loss: 0.162\n",
      "[4,   900] loss: 0.168\n",
      "[4,  1000] loss: 0.153\n",
      "[4,  1100] loss: 0.155\n",
      "[4,  1200] loss: 0.154\n",
      "[5,   100] loss: 0.154\n",
      "[5,   200] loss: 0.142\n",
      "[5,   300] loss: 0.161\n",
      "[5,   400] loss: 0.137\n",
      "[5,   500] loss: 0.153\n",
      "[5,   600] loss: 0.127\n",
      "[5,   700] loss: 0.146\n",
      "[5,   800] loss: 0.134\n",
      "[5,   900] loss: 0.126\n",
      "[5,  1000] loss: 0.119\n",
      "[5,  1100] loss: 0.125\n",
      "[5,  1200] loss: 0.119\n",
      "[6,   100] loss: 0.138\n",
      "[6,   200] loss: 0.114\n",
      "[6,   300] loss: 0.115\n",
      "[6,   400] loss: 0.123\n",
      "[6,   500] loss: 0.118\n",
      "[6,   600] loss: 0.125\n",
      "[6,   700] loss: 0.113\n",
      "[6,   800] loss: 0.114\n",
      "[6,   900] loss: 0.129\n",
      "[6,  1000] loss: 0.111\n",
      "[6,  1100] loss: 0.102\n",
      "[6,  1200] loss: 0.105\n",
      "Finished Training. Final loss = 0.18399189412593842, Total params = 149798\n",
      "Correct = 9711, Total = 10000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transform\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(1,64,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(64,128,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(128,64,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                )\n",
    "        self.classification_head = nn.Sequential(nn.Linear(64,20,bias=True),\n",
    "                                                 nn.ReLU(),\n",
    "                                                 nn.Linear(20,10,bias=True),)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        features = self.net(x)\n",
    "        return self.classification_head(features.view(batch_size,-1))\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root=\"./data\",download = True,train=True,transform=ToTensor())\n",
    "train_loader = DataLoader(mnist_trainset,batch_size=50,shuffle=True)\n",
    "mnist_testset = datasets.MNIST(root=\"./data\",download = True,train=False,transform=ToTensor())\n",
    "test_loader = DataLoader(mnist_testset,batch_size=50,shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNClassifier().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "batch_size=50\n",
    "\n",
    "total_params = 0\n",
    "for name,param in model.named_parameters():\n",
    "    params = param.numel()\n",
    "    total_params += params\n",
    "\n",
    "for epoch in range(6):  \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  \n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(f\"Finished Training. Final loss = {loss.item()}, Total params = {total_params}\")\n",
    "\n",
    "correct,total = 0,0\n",
    "for i,vdata in enumerate(test_loader):\n",
    "    tinputs,tlabels = vdata[0].to(device), vdata[1].to(device)\n",
    "    toutputs = model(tinputs)\n",
    "\n",
    "    _,predicted = torch.max(toutputs,1)\n",
    "    total += tlabels.size(0)\n",
    "    correct += (predicted==tlabels).sum()\n",
    "        \n",
    "print(f\"Correct = {correct}, Total = {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca5a7d9-ed64-4d1d-ab72-ed8c580a6cc9",
   "metadata": {},
   "source": [
    "## Q4\n",
    "\n",
    "Modify CNN of Qn. 3 to reduce the number of parameters in the network. Draw a plot of\n",
    "percentage drop in parameters vs accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c50ee7e0-4821-4662-ad21-4f671aa6744b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.313\n",
      "[1,   200] loss: 2.300\n",
      "[1,   300] loss: 2.287\n",
      "[1,   400] loss: 2.270\n",
      "[1,   500] loss: 2.249\n",
      "[1,   600] loss: 2.204\n",
      "[1,   700] loss: 2.114\n",
      "[1,   800] loss: 1.891\n",
      "[1,   900] loss: 1.515\n",
      "[1,  1000] loss: 1.140\n",
      "[1,  1100] loss: 0.913\n",
      "[1,  1200] loss: 0.829\n",
      "[2,   100] loss: 0.754\n",
      "[2,   200] loss: 0.701\n",
      "[2,   300] loss: 0.642\n",
      "[2,   400] loss: 0.581\n",
      "[2,   500] loss: 0.530\n",
      "[2,   600] loss: 0.526\n",
      "[2,   700] loss: 0.484\n",
      "[2,   800] loss: 0.491\n",
      "[2,   900] loss: 0.457\n",
      "[2,  1000] loss: 0.423\n",
      "[2,  1100] loss: 0.415\n",
      "[2,  1200] loss: 0.398\n",
      "[3,   100] loss: 0.371\n",
      "[3,   200] loss: 0.332\n",
      "[3,   300] loss: 0.363\n",
      "[3,   400] loss: 0.339\n",
      "[3,   500] loss: 0.348\n",
      "[3,   600] loss: 0.330\n",
      "[3,   700] loss: 0.317\n",
      "[3,   800] loss: 0.321\n",
      "[3,   900] loss: 0.287\n",
      "[3,  1000] loss: 0.287\n",
      "[3,  1100] loss: 0.287\n",
      "[3,  1200] loss: 0.282\n",
      "[4,   100] loss: 0.269\n",
      "[4,   200] loss: 0.287\n",
      "[4,   300] loss: 0.243\n",
      "[4,   400] loss: 0.258\n",
      "[4,   500] loss: 0.268\n",
      "[4,   600] loss: 0.240\n",
      "[4,   700] loss: 0.235\n",
      "[4,   800] loss: 0.235\n",
      "[4,   900] loss: 0.246\n",
      "[4,  1000] loss: 0.209\n",
      "[4,  1100] loss: 0.229\n",
      "[4,  1200] loss: 0.241\n",
      "[5,   100] loss: 0.205\n",
      "[5,   200] loss: 0.209\n",
      "[5,   300] loss: 0.243\n",
      "[5,   400] loss: 0.207\n",
      "[5,   500] loss: 0.211\n",
      "[5,   600] loss: 0.194\n",
      "[5,   700] loss: 0.197\n",
      "[5,   800] loss: 0.195\n",
      "[5,   900] loss: 0.197\n",
      "[5,  1000] loss: 0.177\n",
      "[5,  1100] loss: 0.200\n",
      "[5,  1200] loss: 0.197\n",
      "[6,   100] loss: 0.197\n",
      "[6,   200] loss: 0.196\n",
      "[6,   300] loss: 0.182\n",
      "[6,   400] loss: 0.173\n",
      "[6,   500] loss: 0.194\n",
      "[6,   600] loss: 0.187\n",
      "[6,   700] loss: 0.165\n",
      "[6,   800] loss: 0.158\n",
      "[6,   900] loss: 0.161\n",
      "[6,  1000] loss: 0.153\n",
      "[6,  1100] loss: 0.165\n",
      "[6,  1200] loss: 0.165\n",
      "Finished Training. Final loss = 0.20178936421871185, Total params = 9594\n",
      "Correct = 9481, Total = 10000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transform\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class CNNClassifier1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(1,16,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(16,32,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(32,16,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                )\n",
    "        self.classification_head = nn.Sequential(nn.Linear(16,10,bias=True),)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        features = self.net(x)\n",
    "        return self.classification_head(features.view(batch_size,-1))\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root=\"./data\",download = True,train=True,transform=ToTensor())\n",
    "train_loader = DataLoader(mnist_trainset,batch_size=50,shuffle=True)\n",
    "mnist_testset = datasets.MNIST(root=\"./data\",download = True,train=False,transform=ToTensor())\n",
    "test_loader = DataLoader(mnist_testset,batch_size=50,shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model1 = CNNClassifier1().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model1.parameters(), lr=0.01)\n",
    "batch_size=50\n",
    "\n",
    "total_params = 0\n",
    "for name,param in model1.named_parameters():\n",
    "    params = param.numel()\n",
    "    total_params += params\n",
    "\n",
    "for epoch in range(6):  \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model1(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  \n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(f\"Finished Training. Final loss = {loss.item()}, Total params = {total_params}\")\n",
    "\n",
    "correct,total = 0,0\n",
    "for i,vdata in enumerate(test_loader):\n",
    "    tinputs,tlabels = vdata[0].to(device), vdata[1].to(device)\n",
    "    toutputs = model1(tinputs)\n",
    "\n",
    "    _,predicted = torch.max(toutputs,1)\n",
    "    total += tlabels.size(0)\n",
    "    correct += (predicted==tlabels).sum()\n",
    "        \n",
    "print(f\"Correct = {correct}, Total = {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9c000d6-9bbc-4796-bf88-f31189c20dc6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2b95733e454c9fa6a419ab28338516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409eb622d61d4a4c9d155f5c5189086a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e5dadb38b7c440ba28dfc7a065d479e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3dfaf7b54e14ab29b2a3f19079df5c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "[1,   100] loss: 2.311\n",
      "[1,   200] loss: 2.305\n",
      "[1,   300] loss: 2.304\n",
      "[1,   400] loss: 2.301\n",
      "[1,   500] loss: 2.299\n",
      "[1,   600] loss: 2.296\n",
      "[1,   700] loss: 2.292\n",
      "[1,   800] loss: 2.288\n",
      "[1,   900] loss: 2.282\n",
      "[1,  1000] loss: 2.274\n",
      "[1,  1100] loss: 2.263\n",
      "[1,  1200] loss: 2.246\n",
      "[2,   100] loss: 2.218\n",
      "[2,   200] loss: 2.148\n",
      "[2,   300] loss: 1.985\n",
      "[2,   400] loss: 1.739\n",
      "[2,   500] loss: 1.444\n",
      "[2,   600] loss: 1.248\n",
      "[2,   700] loss: 1.089\n",
      "[2,   800] loss: 0.861\n",
      "[2,   900] loss: 0.772\n",
      "[2,  1000] loss: 0.704\n",
      "[2,  1100] loss: 0.561\n",
      "[2,  1200] loss: 0.524\n",
      "[3,   100] loss: 0.454\n",
      "[3,   200] loss: 0.414\n",
      "[3,   300] loss: 0.393\n",
      "[3,   400] loss: 0.357\n",
      "[3,   500] loss: 0.330\n",
      "[3,   600] loss: 0.305\n",
      "[3,   700] loss: 0.319\n",
      "[3,   800] loss: 0.287\n",
      "[3,   900] loss: 0.250\n",
      "[3,  1000] loss: 0.266\n",
      "[3,  1100] loss: 0.256\n",
      "[3,  1200] loss: 0.246\n",
      "[4,   100] loss: 0.230\n",
      "[4,   200] loss: 0.245\n",
      "[4,   300] loss: 0.229\n",
      "[4,   400] loss: 0.207\n",
      "[4,   500] loss: 0.204\n",
      "[4,   600] loss: 0.191\n",
      "[4,   700] loss: 0.179\n",
      "[4,   800] loss: 0.204\n",
      "[4,   900] loss: 0.189\n",
      "[4,  1000] loss: 0.176\n",
      "[4,  1100] loss: 0.175\n",
      "[4,  1200] loss: 0.161\n",
      "[5,   100] loss: 0.166\n",
      "[5,   200] loss: 0.157\n",
      "[5,   300] loss: 0.176\n",
      "[5,   400] loss: 0.159\n",
      "[5,   500] loss: 0.148\n",
      "[5,   600] loss: 0.153\n",
      "[5,   700] loss: 0.137\n",
      "[5,   800] loss: 0.138\n",
      "[5,   900] loss: 0.142\n",
      "[5,  1000] loss: 0.136\n",
      "[5,  1100] loss: 0.127\n",
      "[5,  1200] loss: 0.145\n",
      "[6,   100] loss: 0.127\n",
      "[6,   200] loss: 0.119\n",
      "[6,   300] loss: 0.117\n",
      "[6,   400] loss: 0.128\n",
      "[6,   500] loss: 0.118\n",
      "[6,   600] loss: 0.130\n",
      "[6,   700] loss: 0.125\n",
      "[6,   800] loss: 0.126\n",
      "[6,   900] loss: 0.121\n",
      "[6,  1000] loss: 0.115\n",
      "[6,  1100] loss: 0.116\n",
      "[6,  1200] loss: 0.118\n",
      "Finished Training. Final loss = 0.03902818262577057, Total params = 601254\n",
      "[1,   100] loss: 2.311\n",
      "[1,   200] loss: 2.305\n",
      "[1,   300] loss: 2.301\n",
      "[1,   400] loss: 2.299\n",
      "[1,   500] loss: 2.293\n",
      "[1,   600] loss: 2.290\n",
      "[1,   700] loss: 2.283\n",
      "[1,   800] loss: 2.274\n",
      "[1,   900] loss: 2.261\n",
      "[1,  1000] loss: 2.244\n",
      "[1,  1100] loss: 2.198\n",
      "[1,  1200] loss: 2.114\n",
      "[2,   100] loss: 1.920\n",
      "[2,   200] loss: 1.605\n",
      "[2,   300] loss: 1.288\n",
      "[2,   400] loss: 1.070\n",
      "[2,   500] loss: 0.923\n",
      "[2,   600] loss: 0.779\n",
      "[2,   700] loss: 0.685\n",
      "[2,   800] loss: 0.605\n",
      "[2,   900] loss: 0.511\n",
      "[2,  1000] loss: 0.476\n",
      "[2,  1100] loss: 0.439\n",
      "[2,  1200] loss: 0.400\n",
      "[3,   100] loss: 0.374\n",
      "[3,   200] loss: 0.364\n",
      "[3,   300] loss: 0.350\n",
      "[3,   400] loss: 0.327\n",
      "[3,   500] loss: 0.286\n",
      "[3,   600] loss: 0.269\n",
      "[3,   700] loss: 0.267\n",
      "[3,   800] loss: 0.282\n",
      "[3,   900] loss: 0.254\n",
      "[3,  1000] loss: 0.262\n",
      "[3,  1100] loss: 0.264\n",
      "[3,  1200] loss: 0.242\n",
      "[4,   100] loss: 0.229\n",
      "[4,   200] loss: 0.231\n",
      "[4,   300] loss: 0.229\n",
      "[4,   400] loss: 0.216\n",
      "[4,   500] loss: 0.186\n",
      "[4,   600] loss: 0.224\n",
      "[4,   700] loss: 0.208\n",
      "[4,   800] loss: 0.207\n",
      "[4,   900] loss: 0.217\n",
      "[4,  1000] loss: 0.194\n",
      "[4,  1100] loss: 0.194\n",
      "[4,  1200] loss: 0.178\n",
      "[5,   100] loss: 0.196\n",
      "[5,   200] loss: 0.178\n",
      "[5,   300] loss: 0.182\n",
      "[5,   400] loss: 0.194\n",
      "[5,   500] loss: 0.170\n",
      "[5,   600] loss: 0.158\n",
      "[5,   700] loss: 0.163\n",
      "[5,   800] loss: 0.164\n",
      "[5,   900] loss: 0.145\n",
      "[5,  1000] loss: 0.174\n",
      "[5,  1100] loss: 0.159\n",
      "[5,  1200] loss: 0.156\n",
      "[6,   100] loss: 0.166\n",
      "[6,   200] loss: 0.142\n",
      "[6,   300] loss: 0.131\n",
      "[6,   400] loss: 0.147\n",
      "[6,   500] loss: 0.135\n",
      "[6,   600] loss: 0.157\n",
      "[6,   700] loss: 0.149\n",
      "[6,   800] loss: 0.149\n",
      "[6,   900] loss: 0.136\n",
      "[6,  1000] loss: 0.139\n",
      "[6,  1100] loss: 0.149\n",
      "[6,  1200] loss: 0.132\n",
      "Finished Training. Final loss = 0.09705353528261185, Total params = 38150\n",
      "[1,   100] loss: 2.301\n",
      "[1,   200] loss: 2.295\n",
      "[1,   300] loss: 2.284\n",
      "[1,   400] loss: 2.271\n",
      "[1,   500] loss: 2.251\n",
      "[1,   600] loss: 2.207\n",
      "[1,   700] loss: 2.118\n",
      "[1,   800] loss: 1.904\n",
      "[1,   900] loss: 1.522\n",
      "[1,  1000] loss: 1.136\n",
      "[1,  1100] loss: 0.881\n",
      "[1,  1200] loss: 0.727\n",
      "[2,   100] loss: 0.618\n",
      "[2,   200] loss: 0.576\n",
      "[2,   300] loss: 0.489\n",
      "[2,   400] loss: 0.489\n",
      "[2,   500] loss: 0.457\n",
      "[2,   600] loss: 0.434\n",
      "[2,   700] loss: 0.399\n",
      "[2,   800] loss: 0.367\n",
      "[2,   900] loss: 0.384\n",
      "[2,  1000] loss: 0.349\n",
      "[2,  1100] loss: 0.330\n",
      "[2,  1200] loss: 0.340\n",
      "[3,   100] loss: 0.345\n",
      "[3,   200] loss: 0.314\n",
      "[3,   300] loss: 0.298\n",
      "[3,   400] loss: 0.311\n",
      "[3,   500] loss: 0.297\n",
      "[3,   600] loss: 0.286\n",
      "[3,   700] loss: 0.266\n",
      "[3,   800] loss: 0.278\n",
      "[3,   900] loss: 0.251\n",
      "[3,  1000] loss: 0.248\n",
      "[3,  1100] loss: 0.270\n",
      "[3,  1200] loss: 0.247\n",
      "[4,   100] loss: 0.244\n",
      "[4,   200] loss: 0.246\n",
      "[4,   300] loss: 0.234\n",
      "[4,   400] loss: 0.229\n",
      "[4,   500] loss: 0.230\n",
      "[4,   600] loss: 0.237\n",
      "[4,   700] loss: 0.235\n",
      "[4,   800] loss: 0.202\n",
      "[4,   900] loss: 0.201\n",
      "[4,  1000] loss: 0.233\n",
      "[4,  1100] loss: 0.200\n",
      "[4,  1200] loss: 0.206\n",
      "[5,   100] loss: 0.200\n",
      "[5,   200] loss: 0.207\n",
      "[5,   300] loss: 0.189\n",
      "[5,   400] loss: 0.190\n",
      "[5,   500] loss: 0.185\n",
      "[5,   600] loss: 0.185\n",
      "[5,   700] loss: 0.194\n",
      "[5,   800] loss: 0.184\n",
      "[5,   900] loss: 0.179\n",
      "[5,  1000] loss: 0.183\n",
      "[5,  1100] loss: 0.182\n",
      "[5,  1200] loss: 0.175\n",
      "[6,   100] loss: 0.151\n",
      "[6,   200] loss: 0.179\n",
      "[6,   300] loss: 0.171\n",
      "[6,   400] loss: 0.146\n",
      "[6,   500] loss: 0.174\n",
      "[6,   600] loss: 0.168\n",
      "[6,   700] loss: 0.161\n",
      "[6,   800] loss: 0.155\n",
      "[6,   900] loss: 0.153\n",
      "[6,  1000] loss: 0.169\n",
      "[6,  1100] loss: 0.181\n",
      "[6,  1200] loss: 0.155\n",
      "Finished Training. Final loss = 0.06044217571616173, Total params = 9594\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transform\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root=\"./data\",download = True,train=True,transform=ToTensor())\n",
    "train_loader = DataLoader(mnist_trainset,batch_size=50,shuffle=True)\n",
    "mnist_testset = datasets.MNIST(root=\"./data\",download = True,train=False,transform=ToTensor())\n",
    "test_loader = DataLoader(mnist_testset,batch_size=50,shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "class CNNClassifier1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(1,128,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(128,256,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(256,128,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                )\n",
    "        self.classification_head = nn.Sequential(nn.Linear(128,64,bias=True),\n",
    "                                                 nn.ReLU(),\n",
    "                                                 nn.Linear(64,20,bias=True),\n",
    "                                                 nn.ReLU(),\n",
    "                                                 nn.Linear(20,10,bias=True),)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        features = self.net(x)\n",
    "        return self.classification_head(features.view(batch_size,-1))\n",
    "\n",
    "class CNNClassifier2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(1,32,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(32,64,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(64,32,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                )\n",
    "        self.classification_head = nn.Sequential(nn.Linear(32,20,bias=True),\n",
    "                                                 nn.ReLU(),\n",
    "                                                 nn.Linear(20,10,bias=True),)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        features = self.net(x)\n",
    "        return self.classification_head(features.view(batch_size,-1))\n",
    "    \n",
    "class CNNClassifier3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(1,16,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(16,32,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(32,16,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                )\n",
    "        self.classification_head = nn.Sequential(nn.Linear(16,10,bias=True),)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        features = self.net(x)\n",
    "        return self.classification_head(features.view(batch_size,-1))\n",
    "\n",
    "model1 = CNNClassifier1().to(device)\n",
    "model2 = CNNClassifier2().to(device)\n",
    "model3 = CNNClassifier3().to(device)\n",
    "optimizer = optim.SGD(model1.parameters(), lr=0.01)\n",
    "batch_size=50\n",
    "loss = None\n",
    "total_params = 0\n",
    "\n",
    "for name,param in model1.named_parameters():\n",
    "    params = param.numel()\n",
    "    total_params += params\n",
    "\n",
    "for epoch in range(6):  \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model1(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  \n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(f\"Finished Training. Final loss = {loss.item()}, Total params = {total_params}\")\n",
    "\n",
    "optimizer = optim.SGD(model2.parameters(), lr=0.01)\n",
    "batch_size=50\n",
    "loss = None\n",
    "total_params = 0\n",
    "\n",
    "for name,param in model2.named_parameters():\n",
    "    params = param.numel()\n",
    "    total_params += params\n",
    "\n",
    "for epoch in range(6):  \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model2(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  \n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(f\"Finished Training. Final loss = {loss.item()}, Total params = {total_params}\")\n",
    "\n",
    "\n",
    "loss = None\n",
    "optimizer = optim.SGD(model3.parameters(), lr=0.01)\n",
    "batch_size=50\n",
    "\n",
    "total_params = 0\n",
    "for name,param in model3.named_parameters():\n",
    "    params = param.numel()\n",
    "    total_params += params\n",
    "\n",
    "for epoch in range(6):  \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model3(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  \n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(f\"Finished Training. Final loss = {loss.item()}, Total params = {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfeb891a-6f7a-4bf5-b9e2-5898f7f63ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21ad908e910>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAGdCAYAAADaPpOnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABY4klEQVR4nO3deVyUdeIH8M8zM8wMIowoNyLikaJ4DgqYVHZgZocdG15g5UVrh7rtlllb2S/Zrba1dvMANW+hTbs22qS2zI1LERTvAxHkkEO5BGaYmef3B0oRaAwCzxyf9+s1r5c9852ZzzyafHyO71cQRVEEERERkZWQSR2AiIiIyBwsL0RERGRVWF6IiIjIqrC8EBERkVVheSEiIiKrwvJCREREVoXlhYiIiKwKywsRERFZFYXUATqLyWRCUVERnJ2dIQiC1HGIiIioHURRRE1NDXx8fCCTte+Yis2Ul6KiIvj5+Ukdg4iIiDqgoKAAffv2bddYmykvzs7OAJq+vIuLi8RpiIiIqD2qq6vh5+fX/HO8PWymvFw7VeTi4sLyQkREZGXMueSDF+wSERGRVWF5ISIiIqvC8kJERERWheWFiIiIrArLCxEREVkVlhciIiKyKiwvREREZFVYXoiIiMiqsLwQERGRVWF5ISIiIqvC8kJERERWheWFiIiIrArLC9mMfafLsDXtPEwmUeooRETUhWxmVWmyb1V1jViwJRP1jUYcKqjEXx8dCbms/SuUEhGR9eCRF7IJ/8osQH2jEQDwSeYFLP04GwajSeJURETUFVheyOqZTCK2pJ4HAEwd6Q2FTMDn2UV4PiEbjSwwREQ2h+WFrN7eU2XIv1QHF7UC7zw2Emtma+EgF/BVTjEWbT8IvYEFhojIlrC8kNXbnJoHAHg82A89lArcM8wTcVHBUCpk2HPsImK2ZaLh6iklIiKyfiwvZNXyyq/gh5NlEAQgKsy/efukoR7YMCcYKoUM/z1RigVbWWCIiGxFh8rL6tWrERAQALVaDa1Wi3379l13bHFxMWbOnIkhQ4ZAJpNh8eLFbY5btWoVhgwZAkdHR/j5+WHJkiVoaGjoSDyyI1vTmq51mTTEA/59nFo8Fz7YHR89OQ6ODnL8eKoMT23ajzq9QYqYRETUicwuL4mJiVi8eDGWL1+OrKwshIeHY8qUKcjPz29zvE6ng7u7O5YvX45Ro0a1OWb79u146aWX8Nprr+H48ePYsGEDEhMTsWzZMnPjkR2p0xvw8YECAED0L466/NKEgW7Y/NR4OCnlSDlbgSc+2o9aHQsMEZE1M7u8vPfee5g7dy7mzZuHwMBArFq1Cn5+flizZk2b4/v374/3338f0dHR0Gg0bY5JTU3FrbfeipkzZ6J///6IiIjAjBkzcODAAXPjkR35LKsINQ0G9O/TA7cNdr/uuPEBvbF1XgicVQpknLuEORszUNPQ2I1JiYioM5lVXvR6PTIzMxEREdFie0REBFJSUjocYuLEicjMzERGRgYAIDc3F0lJSZg6dep1X6PT6VBdXd3iQfZDFEVsuXqhblRYf8h+Y0K6sf1csX1+CFzUCmSev4zZGzJQVccCQ0RkjcwqL+Xl5TAajfD09Gyx3dPTEyUlJR0OMX36dLz55puYOHEiHBwcMHDgQEyaNAkvvfTSdV8TGxsLjUbT/PDz8+vw55P1ST93CSdKauDoIMdj2r7tes3Ivr2wY34oXHs44FBBJWZtSMPlK/ouTkpERJ2tQxfsCkLLf+WKothqmzl++OEHvPXWW1i9ejUOHjyI3bt349///jfefPPN675m2bJlqKqqan4UFBR0+PPJ+lw76vLwWF9oHB3a/bogXw12LghFHycljhRWY0Z8GipqdV2UkoiIuoJZ5cXNzQ1yubzVUZbS0tJWR2PM8eqrryIqKgrz5s3DiBEj8PDDD2PlypWIjY2FydT2BGMqlQouLi4tHmQfiqvq8c3RiwCuf6HujQz1ckHCglC4O6twoqQG0+PSUFrDO9uIiKyFWeVFqVRCq9UiOTm5xfbk5GRMmDChwyHq6uogk7WMIpfLIYoiRJErBFNLO9LzYTSJCAnojaFeHSutgz2dkbggFF4uapwurcX0uDRcrGaBISKyBmafNlq6dCnWr1+PjRs34vjx41iyZAny8/MRExMDoOl0TnR0dIvXZGdnIzs7G7W1tSgrK0N2djaOHTvW/PwDDzyANWvWICEhAefOnUNycjJeffVVPPjgg5DL5Tf5FcmW6AxG7Mxoui1/zoT+N/VeA9x7InFhKHx7OSK37Aoi16WiqLK+E1ISEVFXUpj7gsjISFRUVGDFihUoLi5GUFAQkpKS4O/fdPi+uLi41ZwvY8aMaf51ZmYmduzYAX9/f+Tl5QEAXnnlFQiCgFdeeQWFhYVwd3fHAw88gLfeeusmvhrZoq9zSlBeq4e3Ro2IYR0/VXmNfx8nJCwIxcz1acirqENkXCp2zAuFX+8enZCWiIi6giDayHmZ6upqaDQaVFVV8foXG/bw6p+QlV+JFyJuwTN3Du609y2qrMfM+KYC49vLETvmh7SasZeIiDpfR35+c20jshqHL1QiK78SSrkM08f369T39unliMSFYRjg7oTCynpErkvD2bLaTv0MIiLqHCwvZDW2pDatYzR1pDfceqo6/f09XdRIXBCGWzx7oqS6AdPj0nD6Yk2nfw4REd0clheyCpeu6PHFoSIAHbs9ur3cnVXYOT8UQ72cUVajw/S4NJwo4ezNRESWhOWFrELC/nzoDSaM7KvBaL9eXfpZfXo2FZggXxdUXNFjRlwajhRWdelnEhFR+7G8kMUzGE3YntZ0B1t0WP+bms25vVydlNg+LxSj/Hrhcl0jZsan4VBBZZd/LhER/TaWF7J4350oRWFlPVx7OOD+kd7d9rkaRwdsmzseWn9XVDcYMHt9OjLPX+62zycioraxvJDFu7aO0fTx/aB26N5JC53VDtjy1HiMD+iNGp0B0RvSsT/vUrdmICKillheyKKdKa3BT2cqIBOAWSGde3t0ezmpFNj05DjcOqgPruiNiN6QgZSz5ZJkISIilheycNduj75nmCf6uko3620PpQIb5ozDbbe4o77RiCc/2o8fT5VJloeIyJ6xvJDFqmloxK7MCwCAOWH9pQ0DQO0gR1yUFncN9YDOYMK8LQfw/YlSqWMREdkdlheyWLsPFuKK3ohBHj0RNrCP1HEANBWYNbO1mDzcE3qDCQu2HsCeoyVSxyIisissL2SRRFHE5qsX6s4J8++W26PbS6mQ4Z8zx2LqSG80GkX8fvtBfJ1TLHUsIiK7wfJCFumnMxXILbuCnioFHh7bV+o4rTjIZXg/cjSmjfaBwSTimZ1ZzTMAExFR12J5IYu0KSUPAPCYti96qhTShrkOhVyGvz0+Go9p+8JoErE4IQu7D16QOhYRkc1jeSGLU3CpDt+duAgAmB3adesYdQa5TMDbj47EjPF+MInAH/51CB/vL5A6FhGRTWN5IYuzLf08RBEIH+yGQR49pY7zm2QyAW9NG4HoMH+IIvCnXYexLe281LGIiGwWywtZlIZGIxKvHrmItoDbo9tLJhPwxoPD8dStAQCAVz47go9+OidxKiIi28TyQhbli0NFqKxrhG8vR9w51EPqOGYRBAGv3h+IhbcPAAC88eUxxP+YK3EqIiLbw/JCFkMURWy+eqFuVJg/5DLLuT26vQRBwEv3DsWzdw4CALyVdBwffn9G4lRERLaF5YUsxsH8ShwtqoZKIUNksJ/UcTpMEAT8IWIIlt5zCwDgnW9OYtW3pyCKosTJiIhsA8sLWYxrq0c/NNoHrk5KacN0gufuGowX7x0KAFj17Wn8bQ8LDBFRZ2B5IYtQWtOApKuz1FrThbq/5ek7BuKVqYEAgH9+fwaxX59ggSEiukksL2QREjIK0GgUofV3RZCvRuo4nWpe+ACseGg4ACDux1y88eUxFhgiopvA8kKSazSasD29aV6U6DDLnpSuo6LD+mPlwyMANM0e/OrnR2AyscAQEXUEywtJ7pujJbhYrYNbTxWmBHlLHafLzAzph7cfGwlBALal5WPZ7hwWGCKiDmB5IcltSWk66jIzpB+UCtv+I/l4sB/ee3wUZAKQeKAAL3xyCEYWGCIis9j2TwqyeMeKqpGRdwkKmYBZIf2kjtMtHh7TF+9PHwO5TMDug4VYkpgNg9EkdSwiIqvB8kKS2pqWBwCYHOQFTxe1tGG60QOjfPDhzLFwkAv44lARnkvIQiMLDBFRu7C8kGSq6hrxaVYhAGCODd0e3V73BnlhzSwtlHIZknJK8PvtB6EzGKWORURk8VheSDL/yixAQ6MJgd4uGNffVeo4krh7mCfiorVQKmRIPnYRMVsz0dDIAkNEdCMsLyQJk0nEltSmC3XnhPlDEKxvHaPOcscQD2ycMw5qBxm+P1mG+VsOoF7PAkNEdD0sLySJvafKkH+pDi5qBR4a7St1HMlNHOyGTU+ORw+lHPtOl+OpTftRpzdIHYuIyCKxvJAkNl9dxyhynB8clXJpw1iI0AF9sOWp8eipUiA1twJPbNyPWh0LDBHRr7G8ULc7V34FP5wsgyAAs0Ntc0bdjgru3xtb546Hs1qBjLxLiN6QjuqGRqljERFZFJYX6nZbr17rMmmIB/z7OEmcxvKM6eeKHfNCoXF0wMH8SkStT0dVHQsMEdE1HSovq1evRkBAANRqNbRaLfbt23fdscXFxZg5cyaGDBkCmUyGxYsXtzmusrISixYtgre3N9RqNQIDA5GUlNSReGTBrugM+FdmAQDbXceoM4zoq8HO+aHo7aTEoQtVmLk+DZev6KWORURkEcwuL4mJiVi8eDGWL1+OrKwshIeHY8qUKcjPz29zvE6ng7u7O5YvX45Ro0a1OUav1+Oee+5BXl4ePvnkE5w8eRLx8fHw9eWFnLbms+xC1DQY0L9PD9w22F3qOBZtmI8Lds4PhVtPJY4WVWNGfBrKa3VSxyIikpwgiqJZC6uEhIRg7NixWLNmTfO2wMBATJs2DbGxsTd87R133IHRo0dj1apVLbavXbsW77zzDk6cOAEHBwdz4jSrrq6GRqNBVVUVXFxcOvQe1LVEUcS9q/bh5MUavHr/MMydGCB1JKtwprQWM+PTUFqjwyCPntgxLwQedjQbMRHZto78/DbryIter0dmZiYiIiJabI+IiEBKSoo5b9XCF198gbCwMCxatAienp4ICgrCypUrYTRef64LnU6H6urqFg+ybOnnLuHkxRo4OsjxmLav1HGsxiCPnkhcGAZvjRpnSmsxPS4NJVUNUsciIpKMWeWlvLwcRqMRnp6eLbZ7enqipKSkwyFyc3PxySefwGg0IikpCa+88gr+9re/4a233rrua2JjY6HRaJoffn5+Hf586h5brt4e/chYX2gcO3aEzV4FuDkhcUEYfHs5Irf8CiLjUlFYWS91LCIiSXTogt1fz4YqiuJNzZBqMpng4eGBuLg4aLVaTJ8+HcuXL29xaurXli1bhqqqquZHQUFBhz+ful5xVT2+OXoRABBth+sYdYZ+fXogcWEo+vXugfMVdYhcl4qCS3VSxyIi6nZmlRc3NzfI5fJWR1lKS0tbHY0xh7e3N2655RbI5T9PVhYYGIiSkhLo9W3fYaFSqeDi4tLiQZZrR3o+jCYRoQN6Y4iXs9RxrFZf16YCE+DmhAuX6xG5LhV55VekjkVE1K3MKi9KpRJarRbJycktticnJ2PChAkdDnHrrbfizJkzMJlMzdtOnToFb29vKJXKDr8vWQadwYidGU13o9nj6tGdzVvjiMQFoRjo7oSiqgZExqXibFmt1LGIiLqN2aeNli5divXr12Pjxo04fvw4lixZgvz8fMTExABoOp0THR3d4jXZ2dnIzs5GbW0tysrKkJ2djWPHjjU///TTT6OiogLPP/88Tp06ha+++gorV67EokWLbvLrkSVIyilGea0e3ho17hnW8SN09DMPFzUSFoRhiKczLlbrELkuDacu1kgdi4ioWyjMfUFkZCQqKiqwYsUKFBcXIygoCElJSfD3b5pwrLi4uNWcL2PGjGn+dWZmJnbs2AF/f3/k5eUBAPz8/LBnzx4sWbIEI0eOhK+vL55//nm8+OKLN/HVyFJsTmmaUXdWSD8o5JzUubO4O6uwc0EoZq9Px7HiakyPS8O2uSEY5sNTqERk28ye58VScZ4Xy3SooBIPffgTlHIZUpbdCbeeKqkj2ZzKOj2iNmQgp7AKvXo4YNvcEAT5aqSORUTULl0+zwuRubZcXcdo6khvFpcu0quHEtvmhWC0Xy9U1jViZnwasgsqpY5FRNRlWF6oy1TU6vDl4SIAXMeoq2kcHbB17niM6++K6gYDZq9PR+b5S1LHIiLqEiwv1GUSDxRAbzBhZF8NRvv1kjqOzXNWO2DTk+MROqA3anUGRG/IQHpuhdSxiIg6HcsLdQmD0YTtaT/fHn0zkxhS+zmpFPjoifGYOMgNV/RGPPHRfqScKZc6FhFRp2J5oS7x3YlSFFbWo7eTElNHeksdx644KuVYPycYdwxxR32jEU9u2o+9p8qkjkVE1GlYXqhLXFvHaPo4P6gd5DceTJ1O7SDHuigt7g70gM5gwvzNB/Dd8YtSxyIi6hQsL9TpzpTW4KczFZAJwKxQXqgrFZVCjtWztLh3uBf0RhNitmXim6MdX0CViMhSsLxQp7s2Kd09wzzh28tR4jT2TamQ4R8zx+D+kd5oNIpYtP0gvjpcLHUsIqKbwvJCnaq6oRG7Dl4AwHWMLIWDXIZVkaPxyBhfGEwint15EJ9nF0odi4iow1heqFPtzryAOr0Rgzx6ImxgH6nj0FUKuQzv/G4UHg/uC5MILEnMxieZF6SORUTUISwv1GlMJrF5Rt05Yf68PdrCyGUC/vLISMwM6QeTCPzxk0NIyMj/7RcSEVkYlhfqND+dLUdu+RX0VCnw8Ni+UsehNshkAt6aFoQnJvSHKAIv7c7B1qt3hhERWQuWF+o01y7UfUzbFz1VZi9YTt1EEAS89sAwzJsYAAB49fOj2PC/cxKnIiJqP5YX6hQFl+rw3YmmeUSiuI6RxRMEAcunBuLpOwYCAN789zGs23tW4lRERO3D8kKdYlv6eYgiED7YDQPde0odh9pBEAT8afIQPHfXYABA7Ncn8M//npY4FRHRb2N5oZvW0GhE4v4CALw92toIgoCl99yCFyJuAQC8u+cU3ks+BVEUJU5GRHR9LC900744VITKukb0dXXEpKEeUsehDnjmzsFYNmUoAOCD707jnW9OssAQkcVieaGbIooiNqfkAQCiQv0hl/H2aGu18PaB+PP9wwAAq384i5VJx1lgiMgisbzQTTmYfxlHi6qhUsjweLCf1HHoJj01MQBvPjQcABC/7xze+PIYCwwRWRyWF7op126Pfmi0D1ydlBKnoc4QFdYff3lkBAQB2JSSh+WfHYHJxAJDRJaD5YU6rLS6AUk5TYv8RfNCXZsyfXw/vPPYKAgCsCM9Hy/uOgwjCwwRWQiWF+qwnRkFMJhEaP1dEeSrkToOdbLHtH2xKnI0ZALwr8wLeOFfh2AwmqSORUTE8kId02g0YXt60ymjaE5KZ7MeGu2Lf8wYC7lMwKdZhVjy8SE0ssAQkcRYXqhDvjlagtIaHdydVZgS5C11HOpCU0d6Y/WssXCQC/jyUBGe25kFvYEFhoikw/JCHbLl6oW6M8f3g1LBP0a2bvJwL6yL0kIpl+HrIyX4/faD0BmMUsciIjvFnzpktmNF1cjIuwSFTMDMkH5Sx6FucudQT8TPCYZKIcO3xy9i4dZMNDSywBBR92N5IbNtTcsDANwb5AVPF7W0Yahb3X6LOz56YhwcHeT44WQZ5m0+gHo9CwwRdS+WFzJLZZ0en2YVAgDmTOgvbRiSxIRBbtj05Dj0UMrxvzPleHJTBq7oDFLHIiI7wvJCZvnXgQtoaDQh0NsFwf6uUschiYQM6IOtc8ejp0qBtNxLmLMxAzUNjVLHIiI7wfJC7WY0idia1nSh7pwwfwgC1zGyZ1r/3tg2LwTOagUOnL+M6I0ZqKpngSGirsfyQu2291Qp8i/VwUWtwEOjfaWOQxZgtF8v7Jwfil49HJCVX4moDemorNNLHYuIbBzLC7XbtXWMIsf5wVEplzgNWYogXw12zg9FbyclDl+owsz4dFy6wgJDRF2H5YXa5Vz5Few9VQZBAGaHckZdainQ2wUJC0Lh1lOFY8XVmBGXhvJandSxiMhGsbxQu2xNbTrqMmmIB/z7OEmchizRLZ7OSFwYCk8XFU5erMH0uDSUVjdIHYuIbBDLC/2mKzoD/pVZAIC3R9ONDXTvicQFYfDRqHGmtBaRcWkorqqXOhYR2ZgOlZfVq1cjICAAarUaWq0W+/btu+7Y4uJizJw5E0OGDIFMJsPixYtv+N4JCQkQBAHTpk3rSDTqAp9lF6KmwYAANyeED3KTOg5ZuP5uTkhcGAbfXo44V34FkevScOFyndSxiMiGmF1eEhMTsXjxYixfvhxZWVkIDw/HlClTkJ+f3+Z4nU4Hd3d3LF++HKNGjbrhe58/fx4vvPACwsPDzY1FXUQUxeZ1jKJC/SGT8fZo+m1+vXvg45gw9OvdA/mX6hC5Lg35FSwwRNQ5zC4v7733HubOnYt58+YhMDAQq1atgp+fH9asWdPm+P79++P9999HdHQ0NBrNdd/XaDRi1qxZeOONNzBgwABzY1EXScu9hJMXa9BDKcej2r5SxyEr4tvLER8vDMMANycUVtYjMi4V58qvSB2LiGyAWeVFr9cjMzMTERERLbZHREQgJSXlpoKsWLEC7u7umDt3brvG63Q6VFdXt3hQ59uSmgcAeHiMLzSODtKGIavjpVEjYWEoBnv0RHFVAyLXpeJMaa3UsYjIyplVXsrLy2E0GuHp6dliu6enJ0pKSjoc4qeffsKGDRsQHx/f7tfExsZCo9E0P/z8/Dr8+dS2osp67Dl2EQAQHdZf2jBktTyc1di5IBRDvZxRWqPD9LhUnCypkToWEVmxDl2w++tp4UVR7PBU8TU1NZg9ezbi4+Ph5tb+i0GXLVuGqqqq5kdBQUGHPp+ub0d6PowmEaEDemOIl7PUcciKufVUYef8UAz3cUF5rR4z4tNwrIhHS4moYxTmDHZzc4NcLm91lKW0tLTV0Zj2Onv2LPLy8vDAAw80bzOZTE3hFAqcPHkSAwcObPU6lUoFlUrVoc+k36YzGLEzo+ki7Dk86kKdwNVJiR3zQhG9MR2HLlRhRnwats0NwYi+178WjoioLWYdeVEqldBqtUhOTm6xPTk5GRMmTOhQgKFDhyInJwfZ2dnNjwcffBCTJk1CdnY2TwdJJCmnGBVX9PDWqHHPsI4VU6Jf0/RwwNZ5IRjbrxeq6hsxc30asvIvSx2LiKyMWUdeAGDp0qWIiopCcHAwwsLCEBcXh/z8fMTExABoOp1TWFiILVu2NL8mOzsbAFBbW4uysjJkZ2dDqVRi2LBhUKvVCAoKavEZvXr1AoBW26n7XFvHaFZIPyjknMuQOo+L2gFb5obgyY8ysD/vMqI2ZGDTk+MQ3L+31NGIyEqYXV4iIyNRUVGBFStWoLi4GEFBQUhKSoK/f9N6N8XFxa3mfBkzZkzzrzMzM7Fjxw74+/sjLy/v5tJTlzhUUInsgkoo5TJMH99P6jhkg3qqFNj81HjM3XQAqbkViN6YgY1PjEPogD5SRyMiKyCIoihKHaIzVFdXQ6PRoKqqCi4uLlLHsWp/+PgQdh28gEfG+OK9yNFSxyEbVq83YsHWA9h3uhxqBxk2zBmHWzmLM5Fd6cjPb54PoBYqanX48nARACCa6xhRF3NUyhEfHYxJQ9zR0GjCU5v244eTpVLHIiILx/JCLSTsL4DeYMKovhqM9usldRyyA2oHOdZGaXHPME/oDCYs2JKJb6/OL0RE1BaWF2pmMJqwPa3pQl1OSkfdSaWQY/WssbhvhBf0RhNitmXiP0eKpY5FRBaK5YWafXu8FEVVDejtpMTUkd5SxyE74yCX4YPpY/DgKB8YTCIW7cjCl4eKpI5FRBaI5YWaXVvHaPo4P6gd5NKGIbukkMvw98jReGSML4wmEc8nZOHTrAtSxyIiC8PyQgCA0xdrkHK2AjIBmBXqL3UcsmNymYB3fjcKkcF+MInA0o8P4V8HuPwHEf2M5YUAAFtSm651uWeYJ3x7OUqchuydXCYg9pERmB3aD6II/PGTw9iRnv/bLyQiu8DyQqhuaMSug02H5rmOEVkKmUzAmw8F4clb+wMAXv40p/nUJhHZN5YXwu7MC6jTGzHYoyfCBnKGU7IcgiDgz/cPw4LbBgAA/vz5UazflytxKiKSGsuLnTOZxOZTRtET+kMQBIkTEbUkCAKWTRmKRZOaVpf/v6+OY80PZyVORURSYnmxcz+dLUdu+RU4qxR4ZIyv1HGI2iQIAl6IGILFdw8GAPz1PyfwwXenJU5FRFJhebFzm1PyAACPavvCSWX2Op1E3UYQBCy++xb8cfIQAMB7yafwtz0nYSPLsxGRGVhe7FjBpTp8d6JpHZmoMN4eTdZh0aRBWH5fIADgH/89g7/+hwWGyN6wvNixbWnnIYpA+GA3DHTvKXUconabf9sAvP7AMADA2r1n8X9fHWeBIbIjLC92ql5vRML+pom/eHs0WaMnbg3A/00LAgBs+N85vPbFUZhMLDBE9oDlxU59eagIVfWN6OvqiElDPaSOQ9Qhs0P98fajIyEITRMtLv/sCAsMkR1gebFDoihi09ULdaNC/SGX8fZosl6Pj/PD3343CjIB2JmRjz/tOgwjCwyRTWN5sUMH8y/jWHE1VAoZHg/2kzoO0U17ZGxf/D1yNOQyAZ9kXsDSj7NhMJqkjkVEXYTlxQ5tTmmalG7aaF+4OiklTkPUOR4a7Yt/zBgDhUzA59lFeD4xG40sMEQ2ieXFzpRWNyAppxgAb48m23PfCG+snjUWDnIBXx0uxjM7DkJvYIEhsjUsL3ZmZ0YBDCYRwf6uCPLVSB2HqNNFDPdCXFQwlAoZvjl6EU9vy4TOYJQ6FhF1IpYXO6I3mLA9/ed1jIhs1aShHtgwJxgqhQzfnSjFgi2ZaGhkgSGyFSwvduSboyUordHB3VmFe4d7SR2HqEuFD3bHR0+Og6ODHHtPlWHu5v2o17PAENkClhc7siU1DwAwc3w/KBX8rSfbN2GgGzY/NR5OSjl+OlOBJz7KwBWdQepYRHST+BPMThwtqsL+vMtQyATMDOkndRyibjM+oDe2zA2Bs0qB9HOXEL0xAzUNjVLHIqKbwPJiJ7amNl3rcm+QFzxd1BKnIepeWn9XbJsXAhe1ApnnL2P2hgxU1bPAEFkrlhc7UFmnx2fZhQCAObxQl+zUKL9e2DE/FK49HHCooBKz1qehsk4vdSwi6gCWFzvwrwMX0NBoQqC3C4L9XaWOQySZIF8Ndi4IRR8nJY4UVmNGfDoqanVSxyIiM7G82DijScTWtKZTRnPC/CEIXMeI7NtQLxckLAiFu7MKx4urMSM+DWU1LDBE1oTlxcbtPVWK/Et10Dg64KHRvlLHIbIIgz2dkbggFF4uapy6WIvpcam4WN0gdSwiaieWFxt3bR2jyHF+cFTKJU5DZDkGuPdE4sJQ+PZyxNmyK4hcl4qiynqpYxFRO7C82LDcslrsPVUGQQBmh3AdI6Jf8+/jhIQFoejr6oi8ijpExqWi4FKd1LGI6DewvNiwa9e63DnEA/369JA4DZFl8uvdAx8vDIN/nx4ouFSP6XFpOF9xRepYRHQDLC826orOgE8OXADAdYyIfotPL0ckLgjDAHcnFFbWI3JdGnLLaqWORUTXwfJioz7NKkSNzoAANyeED3KTOg6RxfPSqJGwIBSDPXqipLoBkXFpOFNaI3UsImoDy4sNEkWxeR2jqFB/yGS8PZqoPTycmwrMUC9nlNXoELkuDSdKqqWORUS/0qHysnr1agQEBECtVkOr1WLfvn3XHVtcXIyZM2diyJAhkMlkWLx4casx8fHxCA8Ph6urK1xdXXH33XcjIyOjI9EIQFruJZy6WIseSjke1faVOg6RVenTU4Wd80MR5OuCiit6zIhLw9GiKqljEdEvmF1eEhMTsXjxYixfvhxZWVkIDw/HlClTkJ+f3+Z4nU4Hd3d3LF++HKNGjWpzzA8//IAZM2bg+++/R2pqKvr164eIiAgUFhaaG4/w8+rRD4/xhcbRQdowRFbI1UmJ7fNCMcqvFy7XNWJmfDoOX6iUOhYRXSWIoiia84KQkBCMHTsWa9asad4WGBiIadOmITY29oavveOOOzB69GisWrXqhuOMRiNcXV3xz3/+E9HR0e3KVV1dDY1Gg6qqKri4uLTrNbaoqLIe4W9/D6NJxDeLb8MQL2epIxFZreqGRjz50X5knr8MZ5UCm+eOx9h+XGKDqDN15Oe3WUde9Ho9MjMzERER0WJ7REQEUlJSzHmrG6qrq0NjYyN69+593TE6nQ7V1dUtHgTsSM+H0SQibEAfFheim+SidsDmp8ZjfEBv1OgMiFqfjv15l6SORWT3zCov5eXlMBqN8PT0bLHd09MTJSUlnRbqpZdegq+vL+6+++7rjomNjYVGo2l++Pn5ddrnWyudwYidGU2n7+ZM4KR0RJ2hp0qBTU+Ow4SBfXBFb0T0hgyknq2QOhaRXevQBbu/XtxPFMVOW/Dv7bffxs6dO7F7926o1errjlu2bBmqqqqaHwUFBZ3y+dbsq8PFqLiih7dGjbsDPX/7BUTULj2UCmx8Yhxuu8Ud9Y1GPLkpA/tOl0kdi8humVVe3NzcIJfLWx1lKS0tbXU0piPeffddrFy5Env27MHIkSNvOFalUsHFxaXFw95tTm2aUXd2qD8Uct4FT9SZ1A5yxEVpcddQDzQ0mjB38wF8f7JU6lhEdsmsn3BKpRJarRbJycktticnJ2PChAk3FeSdd97Bm2++if/85z8IDg6+qfeyR9kFlThUUAmlXIbIcTyFRtQV1A5yrJmtxeThntAbTFi4JRPJxy5KHYvI7pj9z/OlS5di/fr12LhxI44fP44lS5YgPz8fMTExAJpO5/z6DqHs7GxkZ2ejtrYWZWVlyM7OxrFjx5qff/vtt/HKK69g48aN6N+/P0pKSlBSUoLaWk7P3V7Xbo++f6Q33HqqpA1DZMOUChn+OXMspo7wht5owtPbMvF1TrHUsYjsisLcF0RGRqKiogIrVqxAcXExgoKCkJSUBH//pgtEi4uLW835MmbMmOZfZ2ZmYseOHfD390deXh6Apknv9Ho9HnvssRave+211/D666+bG9HuVNTq8O9DTX95ch0joq7nIJfh/emjoZAL+Dy7CM/szMLfTSIeHOUjdTQiu2D2PC+Wyp7nefnw+zN455uTGNVXg8+fmSh1HCK7YTSJ+NMnh7Hr4AXIBODd343CI2M5qzWRObp8nheyPAajCdvTmi7UjQ7rL20YIjsjlwl457GRmD7ODyYR+MO/DuHj/bzzkairsbxYuW+Pl6KoqgG9nZSYOtJb6jhEdkcmE7Dy4RGICvWHKAJ/2nUY29PPSx2LyKaxvFi5axfqzhjvB7WDXNowRHZKJhOw4qHheOrWAADA8k+PYNNP5yRORWS7WF6s2OmLNUg5WwGZAMwK4Yy6RFISBAGv3h+IhbcPAAC8/uUxrN+XK3EqItvE8mLFNl896hIxzAs+vRylDUNEEAQBL907FM/eOQgA8H9fHcfqH85InIrI9rC8WKnqhkbsPlgIAIjmOkZEFkMQBPwhYgiW3nMLAODt/5zE+9+eho3c2ElkEVherNSuzAuo0xsx2KMnwgb0kToOEf3Kc3cNxp/uHQIA+Pu3p/C3PadYYIg6CcuLFTKZRGy9uo5R9IT+nbYoJhF1rt/fMQivTA0EAPzz+zP4y9cnWGCIOgHLixX635ly5JZfgbNKgUfG+Eodh4huYF74ALzx4HAAwLofc7Hi38dYYIhuEsuLFbp2e/Sj2r5wUpm9wgMRdbM5E/pj5cMjAAAf/ZSHVz8/ApOJBYaoo1herEzBpTp8d6IUABAVxgt1iazFzJB+ePuxkRAEYFtaPl7+NIcFhqiDWF6szLa08xBFIHywGwa695Q6DhGZ4fFgP7z3+CjIBCBhfwH++MlhGFlgiMzG8mJF6vVGJFxdN+UJrh5NZJUeHtMX708fA7lMwK6DF7D042wYjCapYxFZFZYXK/LloSJU1TfCr7cj7hjiIXUcIuqgB0b54MOZY6CQCfg8uwjPJWShkQWGqN1YXqyEKIrYlJIHAIgK9YdcxtujiazZvUHeWDtbC6VchqScEvx++0HoDEapYxFZBZYXK5F5/jKOFVdDpZDh8WA/qeMQUSe4e5gn4qK1UCpkSD52EU9vO4iGRhYYot/C8mIlNl+dlG7aaF/06qGUOA0RdZY7hnhg45xxUDvI8N8TpZi/5QALDNFvYHmxAqXVDfg6pxgAb48mskUTB7th05Pj0UMpx77T5Xhq037U6Q1SxyKyWCwvVmBHRj4MJhHB/q4I8tVIHYeIukDogD7Y8tR49FQpkHK2Ak9s3I9aHQsMUVtYXiyc3mDC9vR8AE3rGBGR7Qru3xtb5o6Hs1qBjLxLiN6QjuqGRqljEVkclhcL983REpTV6ODurMK9w72kjkNEXWxsP1dsnxcCjaMDDuZXImp9OqrqWGCIfonlxcJdW8do5vh+UCr420VkD0b27YUd80Pg2sMBhy5UYeb6NFy+opc6FpHF4E9DC3a0qAr78y5DIRMwK6Sf1HGIqBsN99EgYUEY3HoqcbSoGjPi01Beq5M6FpFFYHmxYFuv3h49ZYQ3PFzUEqchou42xMsZCQvC4OGswomSGsyIS0NpTYPUsYgkx/JioSrr9PgsuxAAMIe3RxPZrUEePZG4MAzeGjVOl9Zi+ro0lFSxwJB9Y3mxUB8fKEBDownDvF2g9XeVOg4RSSjAzQmJC8Lg28sRueVXEBmXisLKeqljEUmG5cUCGU0itqY1nTKaM8EfgsB1jIjsXb8+PZC4MBR+vR1xvqIOketSUXCpTupYRJJgebFAP5wsRcGlemgcHfDgKF+p4xCRhejr2gMfLwxDgJsTLlyuR+S6VOSVX5E6FlG3Y3mxQNfWMYoc5wdHpVziNERkSbw1jkhYEIqB7k4oqmpAZFwqzpbVSh2LqFuxvFiY3LJa/HiqDIIAzA7hhbpE1JqnixoJC8IwxNMZF6t1iFyXhtMXa6SORdRtWF4szLVrXe4c4oF+fXpInIaILJW7swo7F4RimLcLymt1mB6XhuPF1VLHIuoWLC8W5IrOgE8OXADAdYyI6Lf1dlJix/wQjPDVoOKKHjPi03CksErqWERdjuXFgnyaVYganQED3JwQPshN6jhEZAV69VBi27wQjPbrhcq6RsyMT8OhgkqpYxF1KZYXCyGKYvM6RlFh/pDJeHs0EbWPxtEBW+eOR7C/K6obDJi9Ph2Z5y9LHYuoy7C8WIjU3AqculiLHko5HtX2lToOEVkZZ7UDNj81HiEBvVGjMyB6QzrScyukjkXUJTpUXlavXo2AgACo1WpotVrs27fvumOLi4sxc+ZMDBkyBDKZDIsXL25z3K5duzBs2DCoVCoMGzYMn376aUeiWa0tKU0X6j4y1hcuageJ0xCRNXJSKbDpyfGYOMgNV/RGPPHRfqScKZc6FlGnM7u8JCYmYvHixVi+fDmysrIQHh6OKVOmID8/v83xOp0O7u7uWL58OUaNGtXmmNTUVERGRiIqKgqHDh1CVFQUHn/8caSnp5sbzyoVVtZjz7ESAEB0WH9pwxCRVXNUyrF+TjBuv8Ud9Y1GPLlpP348VSZ1LKJOJYiiKJrzgpCQEIwdOxZr1qxp3hYYGIhp06YhNjb2hq+94447MHr0aKxatarF9sjISFRXV+Prr79u3nbvvffC1dUVO3fubFeu6upqaDQaVFVVwcXFpf1fyAK8880JfPj9WYQN6IOdC0KljkNENkBnMGLR9oP49ngplHIZ1kaNxZ1DPaWORdRKR35+m3XkRa/XIzMzExERES22R0REICUlxZy3aiE1NbXVe06ePPmG76nT6VBdXd3iYY0aGo3YmVEAoGkdIyKizqBSyLF6lhb3DveC3mjCwq2Z2HO0ROpYRJ3CrPJSXl4Oo9EIT8+W7d3T0xMlJR3/n6KkpMTs94yNjYVGo2l++Pn5dfjzpZSUU4xLV/Tw1qhxdyD/VUREnUepkOEfM8fg/pHeaDSK+P32g0jKKZY6FtFN69AFu79e5VgUxZte+djc91y2bBmqqqqaHwUFBTf1+VK5to7R7FB/KOS8+YuIOpeDXIZVkaPx8BhfGEwint2Zhc+zC6WORXRTFOYMdnNzg1wub3VEpLS0tNWRE3N4eXmZ/Z4qlQoqlarDn2kJsgsqcaigEkq5DJHjrPPIERFZPoVchnd/NwoKmYB/ZV7AksRsNBpFPMZpGchKmfVPfaVSCa1Wi+Tk5Bbbk5OTMWHChA6HCAsLa/Wee/bsuan3tAbXJqW7f6Q33HpadxEjIssmlwn466MjMWN8P5hE4I+fHEJCRtt3iRJZOrOOvADA0qVLERUVheDgYISFhSEuLg75+fmIiYkB0HQ6p7CwEFu2bGl+TXZ2NgCgtrYWZWVlyM7OhlKpxLBhwwAAzz//PG677Tb89a9/xUMPPYTPP/8c3377Lf73v/91wle0TBW1Ovz7UNO55zlcx4iIuoFMJmDlw0FQygVsTj2Pl3bnoNEkIiqUNwuQdTG7vERGRqKiogIrVqxAcXExgoKCkJSUBH//pj/8xcXFreZ8GTNmTPOvMzMzsWPHDvj7+yMvLw8AMGHCBCQkJOCVV17Bq6++ioEDByIxMREhISE38dUsW8L+AuiNJozy64VRfr2kjkNEdkIQBLz+4HA4yGVY/79zePWzI2g0mPDUxACpoxG1m9nzvFgqa5rnxWQSMfGv/0VRVQPee3wUHhnL885E1L1EUcTb35zEmh/OAgBevm8oFtw2UOJUZI+6fJ4X6hwnL9agqKoBPZRy3DfCW+o4RGSHBEHAnyYPwXN3DQYArEw6gQ+/PyNxKqL2YXmRQMrZpsXSxvXvDbWDXOI0RGSvBEHA0ntuwR/uuQUA8M43J/H35FOwkQPyZMNYXiSQerZpobSwgX0kTkJEBDx712C8NGUoAOD9707jnW9OssCQRWN56WYGownpuZcAABNYXojIQsTcPhCv3t90B+jqH85iZdJxFhiyWCwv3exoUTVqdAY4qxUY7qOROg4RUbO5EwOw4qHhAID4fefwxpfHWGDIIrG8dLNr17uEBPSBXHZzSyoQEXW26LD+iH1kBAQB2JSSh1c+OwKTiQWGLAvLSzdLzW0qLzxlRESWasb4fnjnsVEQBGB7ej5e2n0YRhYYsiAsL91IbzBh/7mr17sMYnkhIsv1mLYvVkWOhkwAPj5wAX/81yEWGLIYLC/d6NCFStQ3GtHbSYlbPJyljkNEdEMPjfbFP2aMhVwmYHdWIRYnZsNgNEkdi4jlpTulXr3eJWxAH8h4vQsRWYGpI73x4cyxcJAL+PJQEZ7dmYVGFhiSGMtLN0rh/C5EZIXuDfLC2tlaKOUyfH2kBE9vOwidwSh1LLJjLC/dpKHRiIPnKwGwvBCR9bkr0BPxc4KhUsjw7fGLWLg1Ew2NLDAkDZaXbnLw/GXojSZ4uqgwwM1J6jhERGa7/RZ3bHxiHNQOMvxwsgzztxxAvZ4Fhrofy0s3uTa/y4SBbhAEXu9CRNbp1kFu2PzkePRQyrHvdDme3JSBKzqD1LHIzrC8dJPm610G8JQREVm3kAF9sHXuePRUKZCWewlPfJSBWhYY6kYsL92gVmfA4QtVAHi9CxHZBq1/b2ybFwJntQL78y4jakM6qhsapY5FdoLlpRvsz7sEg0lEX1dH+PXuIXUcIqJOMdqvF3bOD0WvHg7Iyq/E7PXpqKpjgaGux/LSDdLOckkAIrJNQb4a7JgXit5OShy+UIUZ8Wm4dEUvdSyycSwv3eCXF+sSEdmaYT4uSFgQCreeKhwrrsaMuDSU1+qkjkU2jOWli1XVNeJIEa93ISLbdounMxIWhMLDWYWTF2swPS4NpdUNUsciG8Xy0sXSz1VAFIEB7k7wdFFLHYeIqMsM8uiJjxeGwUejxpnSWkTGpaG4ql7qWGSDWF66WAqvdyEiO9LfzQmJC8Pg28sR58qvIHJdGi5crpM6FtkYlpcu9vNijLzehYjsg1/vHvg4Jgz9evdA/qU6RK5LQ8ElFhjqPCwvXai8VoeTF2sAAKEDekuchoio+/j2csTHC8MwwM0JhZX1eHxdKvLKr0gdi2wEy0sXSsttOuoy1MsZfXqqJE5DRNS9vDRqJCwIxSCPniiuasDj61JxprRW6lhkA1heutC16114lxER2SsPl6YCM9TLGaU1OkyPS8XJkhqpY5GVY3npQmmc34WICG49VdgxPxTDvF1QXqvHjPg0HCuqljoWWTGWly5SXFWP3PIrkAnA+ABe70JE9q23kxI754diVF8NLl1pKjA5V9d8IzIXy0sXuXaXUZCvBhpHB4nTEBFJT9PDAVvnhWBsv16oqm/EzPVpyMq/LHUsskIsL10klde7EBG14qJ2wJa5IRjX3xU1DQZEbcjAgbxLUsciK8Py0gVEUeR6RkRE19FTpcDmp8YjbEAf1OoMiN6YgfSrd2cStQfLSxcouFSPwsp6KGQCgv1dpY5DRGRxeigV2PjEOIQPdkOd3og5H2XgpzPlUsciK8Hy0gVSc5v+Bxzt1wtOKoXEaYiILJOjUo746GBMGuKOhkYTntq0Hz+cLJU6FlkBlpcuwPldiIjaR+0gx9ooLe4Z5gmdwYQFWzLx3fGLUsciC8fy0slEUeTFukREZlAp5Fg9ayzuG+EFvdGEmG2Z+M+REqljkQXrUHlZvXo1AgICoFarodVqsW/fvhuO37t3L7RaLdRqNQYMGIC1a9e2GrNq1SoMGTIEjo6O8PPzw5IlS9DQ0NCReJI6W3YFpTU6KBUyjO3H612IiNrDQS7DB9PH4MFRPmg0ili04yD+fbhI6lhkocwuL4mJiVi8eDGWL1+OrKwshIeHY8qUKcjPz29z/Llz53DfffchPDwcWVlZePnll/Hcc89h165dzWO2b9+Ol156Ca+99hqOHz+ODRs2IDExEcuWLev4N5NI6tmm6120/VyhdpBLnIaIyHoo5DL8PXI0HhnjC6NJxHM7s/BZVqHUscgCmX016XvvvYe5c+di3rx5AJqOmHzzzTdYs2YNYmNjW41fu3Yt+vXrh1WrVgEAAgMDceDAAbz77rt49NFHAQCpqam49dZbMXPmTABA//79MWPGDGRkZHT0e0kmNffaLdI8ZUREZC65TMA7vxsFB7kMiQcKsOTjbBhMIh7T9pU6GlkQs4686PV6ZGZmIiIiosX2iIgIpKSktPma1NTUVuMnT56MAwcOoLGxEQAwceJEZGZmNpeV3NxcJCUlYerUqebEk5zJ9PP1LhMGsbwQEXWEXCYg9pERmBXSD6II/PGTQ9iZ0fbRfbJPZh15KS8vh9FohKenZ4vtnp6eKClp++KqkpKSNscbDAaUl5fD29sb06dPR1lZGSZOnAhRFGEwGPD000/jpZdeum4WnU4HnU7X/N/V1dIv8nWipAaX6xrRQynHyL69pI5DRGS1ZDIB/zctCA5yGTal5GHZ7hw0Gk2IDusvdTSyAB26YFcQhBb/LYpiq22/Nf6X23/44Qe89dZbWL16NQ4ePIjdu3fj3//+N958883rvmdsbCw0Gk3zw8/PryNfpVNdO2U0rn9vOMh5IxcR0c0QBAGvPTAM88MDAAB//vwo1u/LlTgVWQKzfsK6ublBLpe3OspSWlra6ujKNV5eXm2OVygU6NOn6dTKq6++iqioKMybNw8jRozAww8/jJUrVyI2NhYmk6nN9122bBmqqqqaHwUFBeZ8lS5x7WJdXu9CRNQ5BEHAy/cFYtGkgQCA//vqONbuPStxKpKaWeVFqVRCq9UiOTm5xfbk5GRMmDChzdeEhYW1Gr9nzx4EBwfDwaFpteW6ujrIZC2jyOVyiKLYfJTm11QqFVxcXFo8pGQwmpCe27S4GOd3ISLqPIIg4IWIIVh892AAwF++PoF/fHda4lQkJbPPbSxduhTr16/Hxo0bcfz4cSxZsgT5+fmIiYkB0HREJDo6unl8TEwMzp8/j6VLl+L48ePYuHEjNmzYgBdeeKF5zAMPPIA1a9YgISEB586dQ3JyMl599VU8+OCDkMut43bjo0XVqNEZ4KxWYLiPRuo4REQ2RRAELL77Fvxx8hAAwN+ST+G9PSev+w9csm1m3yodGRmJiooKrFixAsXFxQgKCkJSUhL8/f0BAMXFxS3mfAkICEBSUhKWLFmCDz/8ED4+Pvjggw+ab5MGgFdeeQWCIOCVV15BYWEh3N3d8cADD+Ctt97qhK/YPa4tCRA6oA/ksutf/0NERB23aNIgOMgFrEw6gQ/+ewaNJhF/mjzkhtddku0RRBuprdXV1dBoNKiqqpLkFFLUhnTsO12OP98/DE9NDOj2zycisicf/XQOb3x5DAAwb2IAlk8NZIGxUh35+c1bYjqB3mDCgbzLADi/CxFRd3jy1gC8OS0IALD+f+fw+hdHYTLZxL/FqR1YXjrBoQuVqG80oo+TErd4OEsdh4jILkSF+uOvj46AIACbU89j+WdHWGDsBMtLJ0g58/P1LjJe70JE1G0ix/XDu4+NgkwAdmbk40+7DsPIAmPzWF46QWpu0/wuvEWaiKj7Parti79HjoZcJuCTzAv4w8fZMBjbniOMbAPLy01qaDTi4PlKACwvRERSeWi0L/4xYwwUMgGfZRdhcWI2GllgbBbLy006eP4y9EYTPF1UGODmJHUcIiK7dd8Ib6yeNRYOcgH/PlyMZ3dkQW9ggbFFLC836dr8LhMGuvE2PSIiiUUM90JcVDCUChn+c7QEv9+eCZ3BKHUs6mQsLzcp5ep6RmEDeMqIiMgSTBrqgfXRwVApZPj2eCkWbMlEQyMLjC1hebkJtToDDl+oAsDrXYiILMltt7jjoyfGwdFBjr2nyjB3837U61lgbAXLy03Yn3cJBpMIv96O8OvdQ+o4RET0CxMGuWHzU+PhpJTjpzMVeOKjDFzRGaSORZ2A5eUmpF693oWnjIiILNP4gN7YMjcEzioF0s9dwpyNGahpaJQ6Ft0klpebkPqLi3WJiMgyaf1dsW1eCFzUChw4fxlRGzJQVc8CY81YXjqoqq4RR4p4vQsRkTUY5dcLO+aHolcPB2QXVGL2+nRU1umljkUdxPLSQWnnKiCKwAB3J3i6qKWOQ0REvyHIV4Od80PRx0mJnMIqzIhPx6UrLDDWiOWlg34+ZcSjLkRE1iLQ2wUJC0Lh1lOF48XVmB6XirIandSxyEwsLx3E612IiKzTYE9nJC4MhaeLCqcu1mJ6XCouVjdIHYvMwPLSAeW1Opy8WAOgaSVpIiKyLgPdeyJxQRh8NGqcLbuCyHWpKKqslzoWtRPLSwek5TYddRnq5YzeTkqJ0xARUUf0d3NC4sIw9HV1RF5FHSLjUlFwqU7qWNQOLC8dcG09I95lRERk3fx698DHC8Pg36cHCi7VY3pcGvIrWGAsHctLB/B6FyIi2+HTyxGJC8IwwN0JhZX1eHxdKs6VX5E6Ft0Ay4uZiqvqca78CmRC08yNRERk/bw0aiQsCMVgj54oqW5A5LpUnCmtkToWXQfLi5muHXUJ8tVA4+ggcRoiIuosHs5NBWaolzNKa3SYHpeGkyUsMJaI5cVMvN6FiMh29empws75oRju44LyWj2mx6Xi6NXZ1MlysLyYQRRFXu9CRGTjXJ2U2DEvFKP8euFyXSNmxqfj8IVKqWPRL7C8mKHgUj0KK+uhkAkI9neVOg4REXURTQ8HbJ07Hlp/V1TVN2JWfDoO5l+WOhZdxfJihtTccgDAaL9ecFIpJE5DRERdyUXtgM1Pjcf4gN6o0RkQvSED+/MuSR2LwPJilhSuZ0REZFd6qhTY9OQ4TBjYB7U6A+ZszGi+fICkw/LSTqIoNpeXUJYXIiK70UOpwMYnxiF8sBvq9EY8uSkD/ztdLnUsu8by0k5ny66grEYHpUKGsf14vQsRkT1RO8gRHx2MO4d6oKHRhKc278cPJ0uljmW3WF7aKfVsU8sO9neF2kEucRoiIupuagc51s7WImKYJ/QGExZsycS3xy5KHcsusby0U/P8LlxFmojIbikVMnw4ayymjvCG3mhCzLZMfJ1TLHUsu8Py0g4mk9i8kvSEQSwvRET2zEEuw/vTR+Oh0T4wmEQ8szMLXx4qkjqWXWF5aYcTJTW4XNeIHko5RvbtJXUcIiKSmEIuw3uPj8ajY/vCaBLxfEIWPs26IHUsu8Hy0g4pV693Gde/Nxzk3GVERATIZQLeeWwkpo/zg0kEln58CB8fKJA6ll3gT+J2aD5lxFukiYjoF2QyASsfHoGoUH+IIvCnTw5jR3q+1LFsHsvLbzAYTUjPbZpRkYsxEhHRr8lkAlY8NBxP3tofAPDypznYnJInaSZb16Hysnr1agQEBECtVkOr1WLfvn03HL93715otVqo1WoMGDAAa9eubTWmsrISixYtgre3N9RqNQIDA5GUlNSReJ3qSFE1anQGOKsVGO6jkToOERFZIEEQ8Of7h2HhbQMAAK99cRTr9+VKnMp2mV1eEhMTsXjxYixfvhxZWVkIDw/HlClTkJ/f9mGyc+fO4b777kN4eDiysrLw8ssv47nnnsOuXbuax+j1etxzzz3Iy8vDJ598gpMnTyI+Ph6+vr4d/2ad5No00KED+kAuEyROQ0RElkoQBLw0ZSievXMQAOD/vjqO1T+ckTiVbRJEURTNeUFISAjGjh2LNWvWNG8LDAzEtGnTEBsb22r8iy++iC+++ALHjx9v3hYTE4NDhw4hNTUVALB27Vq88847OHHiBBwcHDr0Raqrq6HRaFBVVQUXF5cOvUdbojakY9/pcvz5/mF4amJAp70vERHZrg++O433kk8BAJbcfQuev3uwxIksV0d+fpt15EWv1yMzMxMREREttkdERCAlJaXN16SmprYaP3nyZBw4cACNjY0AgC+++AJhYWFYtGgRPD09ERQUhJUrV8JoNF43i06nQ3V1dYtHV+ihlMPRQc75XYiIqN2eu2sw/nTvEADA3789hb/tOQkzjxXQDSjMGVxeXg6j0QhPT88W2z09PVFSUtLma0pKStocbzAYUF5eDm9vb+Tm5uK///0vZs2ahaSkJJw+fRqLFi2CwWDAn//85zbfNzY2Fm+88YY58TtkXVQw9AYTHOQ8ZURERO33+zsGQSmX4f++Oo5//PcM9EYTXrp3KASBP09uVocu2P31jhdF8Ya/GW2N/+V2k8kEDw8PxMXFQavVYvr06Vi+fHmLU1O/tmzZMlRVVTU/Cgq67t56pULGP2xERGS2eeED8MaDwwEA6/bm4s1/H+cRmE5g1pEXNzc3yOXyVkdZSktLWx1ducbLy6vN8QqFAn36NJ2K8fb2hoODA+Tynxc8DAwMRElJCfR6PZRKZav3ValUUKlU5sQnIiLqdnMm9IdCLmD5p0ew8adzaDSa8MaDwyHjTSAdZtaRF6VSCa1Wi+Tk5Bbbk5OTMWHChDZfExYW1mr8nj17EBwc3Hxx7q233oozZ87AZDI1jzl16hS8vb3bLC5ERETWZFaIP95+dCQEAdiadh4vf5oDk4lHYDrK7NNGS5cuxfr167Fx40YcP34cS5YsQX5+PmJiYgA0nc6Jjo5uHh8TE4Pz589j6dKlOH78ODZu3IgNGzbghRdeaB7z9NNPo6KiAs8//zxOnTqFr776CitXrsSiRYs64SsSERFJ7/Fxfnjv8VGQCUDC/gL88ZPDMLLAdIhZp40AIDIyEhUVFVixYgWKi4sRFBSEpKQk+Pv7AwCKi4tbzPkSEBCApKQkLFmyBB9++CF8fHzwwQcf4NFHH20e4+fnhz179mDJkiUYOXIkfH198fzzz+PFF1/shK9IRERkGR4e0xcKmQyLE7Ox6+AFGEwm/O13o6DgunlmMXueF0vVVfO8EBERdbb/HCnGMzuyYDCJmDrCG6umj7bbhX+7fJ4XIiIiunn3Bnlj7WwtlHIZvsopxqLtB6E3mH77hQSA5YWIiEgSdw/zxLpoLZQKGfYcu4iYbZloaLz+5Kz0M5YXIiIiiUwa4oGNc8ZB7SDDf0+UYsFWFpj2YHkhIiKS0MTBbvjoifHooZTjx1NleGrTftTpDVLHsmgsL0RERBILG9gHm58aDyelHClnK/DExv2o1bHAXA/LCxERkQUY1783ts4LgbNagYy8S4jekI7qhkapY1kklhciIiILMbafK7bPC4HG0QEH8ysRtSEDVXUsML/G8kJERGRBRvbthR3zQ+DawwGHCioxa0MaLl/RSx3LorC8EBERWZjhPhokLAiDW08ljhRWY0Z8GipqdVLHshgsL0RERBZoiJczEhaEwt1ZhRMlNZgel4bSmgapY1kElhciIiILNcjDGYkLQuHlosbp0lpMj0tDSRULDMsLERGRBRvg3hOJC0Ph28sRuWVXEBmXisLKeqljSYrlhYiIyML593FC4sJQ+PV2xPmKOkSuS0XBpTqpY0mG5YWIiMgK9HXtgY8XhiHAzQkXLtcjcl0qzldckTqWJFheiIiIrIS3xhEJC0Ix0N0JRVUNeHxdKs6W1Uodq9uxvBAREVkRTxc1EhaE4RbPnrhYrcP0uDScvlgjdaxuxfJCRERkZdydVdg5PxSB3i4oq2kqMCdKqqWO1W1YXoiIiKxQn54q7JwfghG+GlRc0WNGXBqOFFZJHatbsLwQERFZqV49lNg2LwSj/Xrhcl0jZsan4VBBpdSxuhzLCxERkRXTODpg69zxCPZ3RXWDAbPXpyPz/GWpY3UplhciIiIr56x2wOanxiMkoDdqdAZEb0hHxrlLUsfqMiwvRERENsBJpcCmJ8dj4iA3XNEbMWdjBlLOlksdq0uwvBAREdkIR6Uc6+cE4/Zb3FHfaMSTH+3Hj6fKpI7V6VheiIiIbIjaQY64aC3uDvSAzmDCvC0H8P2JUqljdSqWFyIiIhujUsixepYWk4d7Qm8wYcHWA9hztETqWJ2G5YWIiMgGKRUy/HPmWEwd6Y1Go4jfbz+IpJxiqWN1CpYXIiIiG+Ugl+H9yNF4eIwvDCYRz+7MwufZhVLHumksL0RERDZMIZfh3d+Nwu+0fWE0iViSmI1dmRekjnVTWF6IiIhsnFwm4K+PjsSM8f1gEoEXPjmExP35UsfqMJYXIiIiOyCTCVj5cBDmhPlDFIEXd+VgW9p5qWN1CMsLERGRnRAEAa8/OBxzJwYAAF757Ag++umcxKnMx/JCRERkRwRBwCtTAxFz+0AAwBtfHkP8j7kSpzIPywsREZGdEQQBL947BM/dOQgA8FbScXz4/RmJU7UfywsREZEdEgQBSyOG4A/33AIAeOebk/h78imIoihxst/G8kJERGTHnr1rMF6aMhQA8P53p/HunpMWX2A6VF5Wr16NgIAAqNVqaLVa7Nu374bj9+7dC61WC7VajQEDBmDt2rXXHZuQkABBEDBt2rSORCMiIiIzxdw+EK/ePwwA8OH3ZxH79QmLLjBml5fExEQsXrwYy5cvR1ZWFsLDwzFlyhTk57d9v/i5c+dw3333ITw8HFlZWXj55Zfx3HPPYdeuXa3Gnj9/Hi+88ALCw8PN/yZERETUYXMnBmDFQ8MBAHE/5uKNL49ZbIERRDOThYSEYOzYsVizZk3ztsDAQEybNg2xsbGtxr/44ov44osvcPz48eZtMTExOHToEFJTU5u3GY1G3H777XjyySexb98+VFZW4rPPPmt3rurqamg0GlRVVcHFxcWcr0RERERX7czIx8uf5kAUgdmh/bDiwSDIZEKXfV5Hfn6bdeRFr9cjMzMTERERLbZHREQgJSWlzdekpqa2Gj958mQcOHAAjY2NzdtWrFgBd3d3zJ07t11ZdDodqqurWzyIiIjo5swY3w9vPzoSggBsS8vHst05MJks6wiMWeWlvLwcRqMRnp6eLbZ7enqipKTtpbZLSkraHG8wGFBeXg4A+Omnn7BhwwbEx8e3O0tsbCw0Gk3zw8/Pz5yvQkRERNfxu2A//P3x0ZAJQOKBArzwySEYLajAdOiCXUFoefhIFMVW235r/LXtNTU1mD17NuLj4+Hm5tbuDMuWLUNVVVXzo6CgwIxvQERERDcybYwvPpgxBnKZgN0HC7E4MRsGo0nqWAAAhTmD3dzcIJfLWx1lKS0tbXV05RovL682xysUCvTp0wdHjx5FXl4eHnjggebnTaamnaNQKHDy5EkMHDiw1fuqVCqoVCpz4hMREZEZ7h/pA4VMhmd3HsSXh4oQNqAPZob0kzqWeUdelEoltFotkpOTW2xPTk7GhAkT2nxNWFhYq/F79uxBcHAwHBwcMHToUOTk5CA7O7v58eCDD2LSpEnIzs7m6SAiIiIJ3RvkhbWztZgxvh+mj7OMn8lmHXkBgKVLlyIqKgrBwcEICwtDXFwc8vPzERMTA6DpdE5hYSG2bNkCoOnOon/+859YunQp5s+fj9TUVGzYsAE7d+4EAKjVagQFBbX4jF69egFAq+1ERETU/e4K9MRdgW2fYZGC2eUlMjISFRUVWLFiBYqLixEUFISkpCT4+/sDAIqLi1vM+RIQEICkpCQsWbIEH374IXx8fPDBBx/g0Ucf7bxvQURERHbD7HleLBXneSEiIrI+XT7PCxEREZHUWF6IiIjIqrC8EBERkVVheSEiIiKrwvJCREREVoXlhYiIiKwKywsRERFZFZYXIiIisiosL0RERGRVWF6IiIjIqrC8EBERkVUxe2FGS3Vtiabq6mqJkxAREVF7Xfu5bc5SizZTXmpqagAAfn5+EichIiIic9XU1ECj0bRrrM2sKm0ymVBUVARnZ2cIgmDWa6urq+Hn54eCggKuSN0O3F/m4f4yH/eZebi/zMP9ZZ6u3l+iKKKmpgY+Pj6Qydp3NYvNHHmRyWTo27fvTb2Hi4sL/yCbgfvLPNxf5uM+Mw/3l3m4v8zTlfurvUdcruEFu0RERGRVWF6IiIjIqrC8AFCpVHjttdegUqmkjmIVuL/Mw/1lPu4z83B/mYf7yzyWuL9s5oJdIiIisg888kJERERWheWFiIiIrArLCxEREVkVlhciIiKyKnZfXlavXo2AgACo1WpotVrs27dP6kg37ccff8QDDzwAHx8fCIKAzz77rMXzoiji9ddfh4+PDxwdHXHHHXfg6NGjLcbodDo8++yzcHNzg5OTEx588EFcuHChxZjLly8jKioKGo0GGo0GUVFRqKysbDEmPz8fDzzwAJycnODm5obnnnsOer2+xZicnBzcfvvtcHR0hK+vL1asWGHWGhc3KzY2FuPGjYOzszM8PDwwbdo0nDx5ssUY7rOfrVmzBiNHjmyesCosLAxff/118/PcVzcWGxsLQRCwePHi5m3cZz97/fXXIQhCi4eXl1fz89xXbSssLMTs2bPRp08f9OjRA6NHj0ZmZmbz8za330Q7lpCQIDo4OIjx8fHisWPHxOeff150cnISz58/L3W0m5KUlCQuX75c3LVrlwhA/PTTT1s8/5e//EV0dnYWd+3aJebk5IiRkZGit7e3WF1d3TwmJiZG9PX1FZOTk8WDBw+KkyZNEkeNGiUaDIbmMffee68YFBQkpqSkiCkpKWJQUJB4//33Nz9vMBjEoKAgcdKkSeLBgwfF5ORk0cfHR3zmmWeax1RVVYmenp7i9OnTxZycHHHXrl2is7Oz+O6773bdDvqVyZMnix999JF45MgRMTs7W5w6darYr18/sba2tnkM99nPvvjiC/Grr74ST548KZ48eVJ8+eWXRQcHB/HIkSOiKHJf3UhGRobYv39/ceTIkeLzzz/fvJ377GevvfaaOHz4cLG4uLj5UVpa2vw891Vrly5dEv39/cUnnnhCTE9PF8+dOyd+++234pkzZ5rH2Np+s+vyMn78eDEmJqbFtqFDh4ovvfSSRIk636/Li8lkEr28vMS//OUvzdsaGhpEjUYjrl27VhRFUaysrBQdHBzEhISE5jGFhYWiTCYT//Of/4iiKIrHjh0TAYhpaWnNY1JTU0UA4okTJ0RRbCpRMplMLCwsbB6zc+dOUaVSiVVVVaIoiuLq1atFjUYjNjQ0NI+JjY0VfXx8RJPJ1Il7ov1KS0tFAOLevXtFUeQ+aw9XV1dx/fr13Fc3UFNTIw4ePFhMTk4Wb7/99ubywn3W0muvvSaOGjWqzee4r9r24osvihMnTrzu87a43+z2tJFer0dmZiYiIiJabI+IiEBKSopEqbreuXPnUFJS0uJ7q1Qq3H777c3fOzMzE42NjS3G+Pj4ICgoqHlMamoqNBoNQkJCmseEhoZCo9G0GBMUFAQfH5/mMZMnT4ZOp2s+nJmamorbb7+9xeRHkydPRlFREfLy8jp/B7RDVVUVAKB3794AuM9uxGg0IiEhAVeuXEFYWBj31Q0sWrQIU6dOxd13391iO/dZa6dPn4aPjw8CAgIwffp05ObmAuC+up4vvvgCwcHB+N3vfgcPDw+MGTMG8fHxzc/b4n6z2/JSXl4Oo9EIT0/PFts9PT1RUlIiUaqud+273eh7l5SUQKlUwtXV9YZjPDw8Wr2/h4dHizG//hxXV1colcobjrn231L8PoiiiKVLl2LixIkICgpqkYP77Gc5OTno2bMnVCoVYmJi8Omnn2LYsGHcV9eRkJCAzMxMxMbGtnqO+6ylkJAQbNmyBd988w3i4+NRUlKCCRMmoKKigvvqOnJzc7FmzRoMHjwY33zzDWJiYvDcc89hy5YtLbLY0n6zmVWlO0oQhBb/LYpiq222qCPf+9dj2hrfGWPEqxdtSfH78Mwzz+Dw4cP43//+1+o57rOfDRkyBNnZ2aisrMSuXbswZ84c7N2794b57HVfFRQU4Pnnn8eePXugVquvO477rMmUKVOafz1ixAiEhYVh4MCB2Lx5M0JDQ6+bzx731TUmkwnBwcFYuXIlAGDMmDE4evQo1qxZg+jo6Btmtdb9ZrdHXtzc3CCXy1u1vNLS0laN0JZcu2r/Rt/by8sLer0ely9fvuGYixcvtnr/srKyFmN+/TmXL19GY2PjDceUlpYCaP2vhK727LPP4osvvsD333+Pvn37Nm/nPmtNqVRi0KBBCA4ORmxsLEaNGoX333+f+6oNmZmZKC0thVarhUKhgEKhwN69e/HBBx9AoVBc91+c9rzPfsnJyQkjRozA6dOn+efrOry9vTFs2LAW2wIDA5Gfnw/ANv8Os9vyolQqodVqkZyc3GJ7cnIyJkyYIFGqrhcQEAAvL68W31uv12Pv3r3N31ur1cLBwaHFmOLiYhw5cqR5TFhYGKqqqpCRkdE8Jj09HVVVVS3GHDlyBMXFxc1j9uzZA5VKBa1W2zzmxx9/bHEb3Z49e+Dj44P+/ft3/g5ogyiKeOaZZ7B7927897//RUBAQIvnuc9+myiK0Ol03FdtuOuuu5CTk4Ps7OzmR3BwMGbNmoXs7GwMGDCA++wGdDodjh8/Dm9vb/75uo5bb7211fQOp06dgr+/PwAb/TusXZf12qhrt0pv2LBBPHbsmLh48WLRyclJzMvLkzraTampqRGzsrLErKwsEYD43nvviVlZWc23gP/lL38RNRqNuHv3bjEnJ0ecMWNGm7fM9e3bV/z222/FgwcPinfeeWebt8yNHDlSTE1NFVNTU8URI0a0ecvcXXfdJR48eFD89ttvxb59+7a4Za6yslL09PQUZ8yYIebk5Ii7d+8WXVxcuvVWw6efflrUaDTiDz/80OL2zLq6uuYx3Gc/W7Zsmfjjjz+K586dEw8fPiy+/PLLokwmE/fs2SOKIvdVe/zybiNR5D77pT/84Q/iDz/8IObm5oppaWni/fffLzo7Ozf/vcx91VpGRoaoUCjEt956Szx9+rS4fft2sUePHuK2bduax9jafrPr8iKKovjhhx+K/v7+olKpFMeOHdt8e6w1+/7770UArR5z5swRRbHptrnXXntN9PLyElUqlXjbbbeJOTk5Ld6jvr5efOaZZ8TevXuLjo6O4v333y/m5+e3GFNRUSHOmjVLdHZ2Fp2dncVZs2aJly9fbjHm/Pnz4tSpU0VHR0exd+/e4jPPPNPi9jhRFMXDhw+L4eHhokqlEr28vMTXX3+9W28zbGtfARA/+uij5jHcZz976qmnmv+fcXd3F++6667m4iKK3Fft8evywn32s2vzjzg4OIg+Pj7iI488Ih49erT5ee6rtn355ZdiUFCQqFKpxKFDh4pxcXEtnre1/SaIooRTTRIRERGZyW6veSEiIiLrxPJCREREVoXlhYiIiKwKywsRERFZFZYXIiIisiosL0RERGRVWF6IiIjIqrC8EBERkVVheSEiIiKrwvJCREREVoXlhYiIiKwKywsRERFZlf8HUlmrhHSQTtUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = [0.03902818262577057,0.08542836457490921,0.09705353528261185,0.06044217571616173]\n",
    "params = [601254,149798,38150,9594]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(params,losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0587c0-b4d4-476a-8b7c-d9e6a528346a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
