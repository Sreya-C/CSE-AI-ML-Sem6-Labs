{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1: Demonstrate how to load a dataset suitable for recommendation systems into a PySpark DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lplab/anaconda3/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+-----+\n",
      "|       user_id|product_id|score|\n",
      "+--------------+----------+-----+\n",
      "|A141HP4LYPWMSR|B003AI2VGA|  3.0|\n",
      "|A328S9RN3U5M68|B003AI2VGA|  3.0|\n",
      "|A1I7QGUDP043DG|B003AI2VGA|  5.0|\n",
      "|A1M5405JH9THP9|B003AI2VGA|  3.0|\n",
      "| ATXL536YX71TR|B003AI2VGA|  3.0|\n",
      "+--------------+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "import findspark\n",
    "findspark.init()\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "ratings = spark.read.json(\"movies 1.json\").select(\"user_id\",\"product_id\",\"score\").cache()\n",
    "ratings = ratings.head(10000)\n",
    "ratings = spark.createDataFrame(ratings)\n",
    "\n",
    "ratings.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2: Implement a PySpark script that splits the data and trains a recommendation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+-----+-------------+----------------+-----------+\n",
      "|user_id       |product_id|score|user_id_index|product_id_index|prediction |\n",
      "+--------------+----------+-----+-------------+----------------+-----------+\n",
      "|A2FRKEXDXDN1KI|B000063W1R|4.0  |31.0         |7.0             |10.497304  |\n",
      "|ADX5JX5LKLC22 |B000063W1R|5.0  |580.0        |7.0             |4.989737   |\n",
      "|A2FEGRJQNU51P9|B000063W1R|4.0  |384.0        |7.0             |-1.6689513 |\n",
      "|A328S9RN3U5M68|B003AI2VGA|3.0  |6.0          |144.0           |-23.98982  |\n",
      "|A13TO1ZFAH9SVN|B000063W1R|5.0  |235.0        |7.0             |-3.2107456 |\n",
      "|A1J03J0HZ7KU5T|B008FPU7AA|2.0  |127.0        |112.0           |-0.73620385|\n",
      "|A3OI841P5R6FCH|B000063W1R|4.0  |523.0        |7.0             |1.8565565  |\n",
      "|AQ01Q3070LT29 |B000063W1R|1.0  |38.0         |7.0             |3.3005426  |\n",
      "|A27RJ30RN5K9MX|B000063W1R|5.0  |145.0        |7.0             |-3.7193491 |\n",
      "|A9Q28YTLYREO7 |B004BH1TN0|4.0  |200.0        |127.0           |0.9626541  |\n",
      "+--------------+----------+-----+-------------+----------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(ratings)\n",
    "    for column in [\"user_id\", \"product_id\"]\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "ratings_indexed = pipeline.fit(ratings).transform(ratings)\n",
    "\n",
    "training_data,validation_data = ratings_indexed.randomSplit([8.0,2.0])\n",
    "\n",
    "als = ALS(userCol=\"user_id_index\",itemCol=\"product_id_index\",ratingCol=\"score\",rank=10,maxIter=5,regParam=0.01,coldStartStrategy=\"drop\")\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\",labelCol=\"score\",predictionCol=\"prediction\")\n",
    "\n",
    "model = als.fit(training_data)\n",
    "predictions=model.transform(validation_data)\n",
    "predictions.show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3: Implement a PySpark script using the ALS algorithm for collaborative filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+-------------+----------------+\n",
      "|product_id|      user_id|user_id_index|product_id_index|\n",
      "+----------+-------------+-------------+----------------+\n",
      "|B0001EYSQC|ANCOMAI0I7LVG|          1.0|            31.0|\n",
      "|B00004RXMK|ANCOMAI0I7LVG|          1.0|            62.0|\n",
      "|B001AQT0VI|ANCOMAI0I7LVG|          1.0|            15.0|\n",
      "|B005UYF7KY|ANCOMAI0I7LVG|          1.0|            50.0|\n",
      "+----------+-------------+-------------+----------------+\n",
      "\n",
      "+----------+-------------+-------------+----------------+-----------+\n",
      "|product_id|      user_id|user_id_index|product_id_index| prediction|\n",
      "+----------+-------------+-------------+----------------+-----------+\n",
      "|B00004RXMK|ANCOMAI0I7LVG|          1.0|            62.0|   8.902909|\n",
      "|B0001EYSQC|ANCOMAI0I7LVG|          1.0|            31.0|-0.68762636|\n",
      "|B001AQT0VI|ANCOMAI0I7LVG|          1.0|            15.0| -10.798508|\n",
      "|B005UYF7KY|ANCOMAI0I7LVG|          1.0|            50.0|  -14.21423|\n",
      "+----------+-------------+-------------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user1 = validation_data.filter(validation_data['user_id_index']==1.0).select(['product_id','user_id','user_id_index','product_id_index'])\n",
    "user1.show()\n",
    "recommendations = model.transform(user1) \n",
    "recommendations.orderBy('prediction',ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4: Implement code to evaluate the performance of the recommendation model using appropriate metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) = 5.7522237109984875\n",
      "Mean Absolute Error (MAE) = 4.264309283829248\n"
     ]
    }
   ],
   "source": [
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) = {rmse}\")\n",
    "\n",
    "# Additional Evaluation Metric: Mean Absolute Error (MAE)\n",
    "evaluator_mae = RegressionEvaluator(\n",
    "    metricName=\"mae\",\n",
    "    labelCol=\"score\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "mae = evaluator_mae.evaluate(predictions)\n",
    "print(f\"Mean Absolute Error (MAE) = {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
